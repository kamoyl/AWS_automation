#!/usr/bin/env bash

if [[ ${VERBOSE} == yes ]]
then
  debug "${YELLOW}[ ${LIME}$(echo $(caller | awk '{print $2}') | awk -F\/ '{print $NF}') ${YELLOW}calls (in line: ${LIME}$(caller | awk '{print $1}')${YELLOW}) ${LIME}$(echo ${BASH_SOURCE} | awk -F\/ '{print $NF}') ${PARAMETERS} ${YELLOW} ]"
fi

#prerequisites variables:
if [ ! -s "${SCRIPTS_HOME}/config_extra" ]
then
  export AWS_DEFAULT_NAME="default"
  export AWS_COMMON_NAME="kamil"
  export AWS_LOGIN_URL="https://aws.amazon.com/"
  export SLACK_CHANNEL_AWS="D1KGVBCUF"
fi
#AWS_NETWORK_TAG="" - if empty - all networks will be picked up
#SOURCE_NETWORKS=""
#SLACK_WEB_HOOK=""
#SLACK_TOKEN=""
#prerequisites variables

if [ -z ${USER} ]
then
  USER="jenkins"
fi
if [ -z ${AWS_REPO_ADDRESS} ]
then
  AWS_REPO_ADDRESS="https://github.com/kamoyl/AWS_automation"
fi

if [[ ${HOSTNAME_FQDN} =~ eu-west-1.compute.internal ]]
then
  AWS_ZONE="Y"
  AWS_ZONE_INFO="YES"
  export YOUR_IP="${DEFAULT_INET_IP}"
  AWS_IP="${YOUR_IP}"
  PROXYS=""
  LOCAL_EC2_INSTANCE=$(cat /sys/devices/virtual/dmi/id/board_asset_tag)
  debug "You are currently connected from ${BROWN}AWS: ${LIME}${YOUR_IP}${BLUE}, instanceID: ${YELLOW}${LOCAL_EC2_INSTANCE}"
else
  AWS_ZONE="N"
  AWS_ZONE_INFO="NO"
fi

if [ -z ${PROXYS} ]
then
  SLACK_PROXY_CONTROL=""
else
  SLACK_PROXY_CONTROL=(-x ${PROXYS})
fi

EXTERNAL_INET_IP=$(timeout --preserve-status -s 9 -k 3 2 curl ${SLACK_PROXY_CONTROL[*]} -s https://ipinfo.io/ip 2>/dev/null)
AWS_NAMES_PREFIX="$(echo ${USER} | awk '{print $1}')"
AWS_HOSTNAME_AZ=$(hostname -f | awk -F\. '{print $2}')
AWS_ACCOUNT="${AWS_NAMES_PREFIX}_account_${CURRENT_TIMESTAMP}"
AWS_AMIS_DETAILS="aws_EC2_amis_${CURRENT_TIMESTAMP}"
AWS_EVENTS_BUSES="aws_events-buses_${CURRENT_TIMESTAMP}"
AWS_EVENTS_RULES="aws_events-rules_${CURRENT_TIMESTAMP}"
AWS_EVENTS_TARGETS="aws_events-targets_${CURRENT_TIMESTAMP}"
AWS_COMPLIANCE="aws_compliance_${CURRENT_TIMESTAMP}"
AWS_COSTS_DETAILS="${AWS_COMMON_NAME}_costs_${CURRENT_TIMESTAMP}"
AWS_EC2_INSTANCES_POLICY="${AWS_COMMON_NAME}-EC2_policy"
AWS_EC2_INSTANCES_PROFILE="${AWS_COMMON_NAME}-EC2_instance_profile"
AWS_EC2_KEYPAIRS="${AWS_COMMON_NAME}_keypairs_${CURRENT_TIMESTAMP}"
AWS_EC2_ROLE="${AWS_COMMON_NAME}-EC2_role"
AWS_IGWS="aws_igws_${CURRENT_TIMESTAMP}"
AWS_INSTANCES_DETAILS="aws_EC2_instance_${CURRENT_TIMESTAMP}"
AWS_INSTANCE_PROFILES="aws_EC2_instance-profiles_${CURRENT_TIMESTAMP}"
AWS_INSTANCE_PROFILES_ASSOCIATIONS="aws_EC2_instance_profile_associations_${CURRENT_TIMESTAMP}"
AWS_LAMBDA_FUNCTIONS="aws_lambda_functions_${CURRENT_TIMESTAMP}"
AWS_EC2_LAMBDA_POLICY="${AWS_COMMON_NAME}-LAMBDA_policy"
AWS_LAMBDA_ROLE="${AWS_COMMON_NAME}-LAMBDA_role"
AWS_EC2_LAMBDA_ROLE="${AWS_COMMON_NAME}-LAMBDA_role"
AWS_LOGS="${AWS_COMMON_NAME}_logs_${CURRENT_TIMESTAMP}"
AWS_LOGS_RETENTION_DAYS="7"
AWS_POLICIES="aws_policies_${CURRENT_TIMESTAMP}"
AWS_POLICIES_ATTACHED_ROLE="aws_policies-attached-role_${CURRENT_TIMESTAMP}"
AWS_POLICY_ENTITIES="aws_policy-entities_${CURRENT_TIMESTAMP}"
AWS_POLICY_VERSION="2012-10-17"
AWS_ROLES="aws_roles_${CURRENT_TIMESTAMP}"
AWS_ROUTE_TBLS="aws_route_tables_${CURRENT_TIMESTAMP}"
AWS_S3BUCKETS_DETAILS="aws_S3_bucks_${CURRENT_TIMESTAMP}"
AWS_S3_BUCKETS=(${AWS_COMMON_NAME}-reports ${AWS_COMMON_NAME}-housekeeping ${AWS_COMMON_NAME}-securitymatrix ${AWS_COMMON_NAME}-trails)
AWS_SECURITY_GROUPS="aws_security-groups_${CURRENT_TIMESTAMP}"
AWS_SNAPS_DETAILS="aws_S3_snaps_${CURRENT_TIMESTAMP}"
AWS_SUBNETS_DETAILS="aws_subnets_${CURRENT_TIMESTAMP}"
AWS_TRAILS="aws_trails_${CURRENT_TIMESTAMP}"
AWS_VOLS_DETAILS="aws_EC2_vols_${CURRENT_TIMESTAMP}"
AWS_VPCS="aws_vpcs_${CURRENT_TIMESTAMP}"
AWS_SNS_TOPICS="aws_sns-topics_${CURRENT_TIMESTAMP}"
AWS_SNS_SUBSC="aws_sns-sunscriptions_${CURRENT_TIMESTAMP}"
SECURITY_GROUP_LAMBDA_NAME="${AWS_COMMON_NAME}_lambda_ec2-sec_group"
if [ ! -z ${EXTERNAL_INET_IP} ]
then
  debug "  And your external IP is: ${LIME}${EXTERNAL_INET_IP}"
  SECURITY_GROUP_EC2_NAME="${AWS_NAMES_PREFIX}_ec2-sec_group-for_${EXTERNAL_INET_IP}"
else
  SECURITY_GROUP_EC2_NAME="${AWS_NAMES_PREFIX}_ec2-sec_group-for_${DEFAULT_INET_IP}"
fi

log_tmp_maintenance()
{
  if [ $# -eq 1 ]
  then
    S3_BUCKET_NAME=${1}
  fi
  BACKUP_OUTPUT_FILE="${SCRIPT_NAME}_${CURRENT_TIMESTAMP}.tar.xz"
  inf "Archiving all logs and tmp files into: ${BROWN}${VAR}/${BACKUP_OUTPUT_FILE}"
  tar -cJf "${VAR}/${BACKUP_OUTPUT_FILE}" -C "${VAR}" ${TMP} ${LOG} > "${VAR}/maintenance_log_tmp.log" 2>&1
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    rm -rf "${TMP}"
    rm -rf "${LOG}"
    inf "  All tmp and log files has just been archived in: ${YELLOW}${VAR}"
    if [[ ${AWS_ZONE} == "Y" ]]
    then
      if [ -z ${S3_BUCKET_NAME} ]
      then
        S3_BUCKET_NAME="${AWS_COMMON_NAME}-reports"
        warn "    ${BROWN}${BACKUP_OUTPUT_FILE}${WINE} - AWS S3 bucket is not provided, so default one is choosen: ${YELLOW}${S3_BUCKET_NAME}"
        inf "    Copying ${BROWN}${BACKUP_OUTPUT_FILE}${CYAN} to AWS S3 bucket: ${YELLOW}${S3_BUCKET_NAME}"
        aws ${AWS_PROFILE_USE_CHECK[*]} s3 cp "${VAR}/${BACKUP_OUTPUT_FILE}" s3://${S3_BUCKET_NAME}/ --storage-class STANDARD_IA > "${VAR}/S3_copying_log_tmp.log" 2>&1
      else
        inf "    Copying ${BROWN}${BACKUP_OUTPUT_FILE}${CYAN} to AWS S3 bucket: ${YELLOW}${S3_BUCKET_NAME}"
        aws ${AWS_PROFILE_USE_CHECK[*]} s3 cp "${VAR}/${BACKUP_OUTPUT_FILE}" s3://${S3_BUCKET_NAME}/ --storage-class STANDARD_IA > "${VAR}/S3_copying_log_tmp.log" 2>&1
      fi
    fi
  else
    inf "  I couldn't archive tmp and log files"
  fi
}

slack_vm_start()
{
LOG="/var/log/aws"
TMP="/tmp"

curl ${SLACK_PROXY_CONTROL[*]} -v -X POST --data "{\"channel\": \"${SLACK_CHANNEL_AWS}\"
  , \"username\": \"${YOUR_IP}\"
  , \"icon_emoji\": \":dancer:\"
  , \"attachments\":
    [
      {
        \"fallback\": \"EC2 (${DEFAULT_INET_IP}, az: ${AWS_HOSTNAME_AZ}) started\",
        \"title\": \"EC2 (${DEFAULT_INET_IP}, az: ${AWS_HOSTNAME_AZ}) started (${NOW})\",
        \"title_link\": \"${AWS_LOGIN_URL}\",
        \"footer\": \"<${AWS_LOGIN_URL}|AWS log in:>\",
        \"footer_icon\": \"https://github.com/quintessence/slack-icons/blob/master/images/amazon-web-services-slack-icon.png\"
      }
    ]
, \"token\": \"${SLACK_TOKEN}\"
}" ${SLACK_WEB_HOOK} > "${LOG}/${CURRENT_TIMESTAMP}_slack.log" 2>&1
}

slack_vm_stop()
{
LOG="/var/log/aws"
TMP="/tmp"

curl ${SLACK_PROXY_CONTROL[*]} -v -X POST --data "{\"channel\": \"${SLACK_CHANNEL_AWS}\"
  , \"username\": \"${YOUR_IP}\"
  , \"icon_emoji\": \":zzz:\"
  , \"attachments\":
    [
      {
        \"fallback\": \"EC2 (${DEFAULT_INET_IP}, az: ${AWS_HOSTNAME_AZ}) stopped\",
        \"title\": \"EC2 (${DEFAULT_INET_IP}, az: ${AWS_HOSTNAME_AZ}) stopped (${NOW})\",
        \"title_link\": \"${AWS_LOGIN_URL}\",
        \"footer\": \"<${AWS_LOGIN_URL}|AWS log in:>\",
        \"footer_icon\": \"https://github.com/quintessence/slack-icons/blob/master/images/amazon-web-services-slack-icon.png\"
      }
    ]
, \"token\": \"${SLACK_TOKEN}\"
}" ${SLACK_WEB_HOOK} > "${LOG}/${CURRENT_TIMESTAMP}_slack.log" 2>&1
}

aws_connectivity_check()
{
  if aws ${AWS_PROFILE_USE_CHECK[*]} sts get-caller-identity > "${TMP}/${AWS_ACCOUNT}_full.json"  2>"${LOG}/${AWS_ACCOUNT}.log"
  then
    export AWS_OWNER_ID=$(jq -r '.Account' "${TMP}/${AWS_ACCOUNT}_full.json")
    export AWS_USER_ID=$(jq -r '.UserId' "${TMP}/${AWS_ACCOUNT}_full.json")
    export AWS_ARN_USER=$(jq -r '.Arn' "${TMP}/${AWS_ACCOUNT}_full.json")
    if [[ ${VERBOSE} == yes ]]
    then
      debug "ownerId: ${WINE}${AWS_OWNER_ID}"
      debug "UserId : ${WINE}${AWS_USER_ID}"
      debug "UserArn: ${WINE}${AWS_ARN_USER}"
    fi
  else
    ERROR_CODE="$?"
    error "It might be you are not authenticated to AWS, or there is a network issue, exiting"
    failed
fi
}

aws_default_subnet()
{
  if [ -s "${TMP}/${AWS_SUBNETS_DETAILS}_full.json" ]
  then
    if [ ! -z $(jq -r '.Subnets[] | .Tags[].Value' "${TMP}/${AWS_SUBNETS_DETAILS}_full.json" 2>/dev/null | head -n1) ]
    then
      debug "  taking subnet based on TAGs"
      SUBNET_ID=$(shuf -e $(jq -r '.Subnets[] | .SubnetId + "~"  + .Tags[].Value' "${TMP}/${AWS_SUBNETS_DETAILS}_full.json" | grep ${AWS_NETWORK_TAG} | awk -F\~ '{print $1}') | tail -n1)
    else
      debug "  taking randomly ANY subnet"
      SUBNET_ID=$(shuf -e $(jq -r '.Subnets[] | .SubnetId' "${TMP}/${AWS_SUBNETS_DETAILS}_full.json") | tail -n1)
    fi
    AVAILABILITY_ZONE=$(jq -r --arg subnet_id ${SUBNET_ID} '.Subnets[] | select(.SubnetId == $subnet_id) | .AvailabilityZone' "${TMP}/${AWS_SUBNETS_DETAILS}_full.json")
    REGION=$(aws ${AWS_PROFILE_USE_CHECK[*]} ec2 describe-availability-zones | jq -r --arg availability_zone ${AVAILABILITY_ZONE} '.AvailabilityZones[] | select(.ZoneName == $availability_zone) | .RegionName')
  else
    error "  There is no AWS Networks... exiting"
    failed
  fi
}

aws_key_create()
{
  inf "${MAGENTA}Preparation of KeyPairs for accessing EC2 deployed instance"
  if [ -s "${HOME}/.ssh/id_rsa" ]
  then
    inf "  I found id_rsa key of current user: ${YELLOW}${USER}${CYAN}, making fingerprint"
    CURRENT_USER_FINGERPRINT=$(ssh-keygen -f ${HOME}/.ssh/id_rsa.pub -e -m PKCS8 | openssl pkey -pubin -outform DER | openssl md5 -c)
    inf "    Checking if current user: ${YELLOW}${USER}${CYAN} fingerprint exists in AWS EC2"
    if [ -s "${TMP}/${AWS_EC2_KEYPAIRS}_full.json" ]
    then
      KEY_FINGERPRINT=$(jq -r --arg KeyFingerprint ${CURRENT_USER_FINGERPRINT} '.KeyPairs[] | select(.KeyFingerprint == $KeyFingerprint) | .KeyFingerprint' "${TMP}/${AWS_EC2_KEYPAIRS}_full.json" | sort -u)
    else
      KEY_FINGERPRINT=""
    fi
    if [ -z ${KEY_FINGERPRINT} ]
    then
      warn "      Current user key doesn't exists in AWS EC2"
      inf "        Importing..."
      KEY_NAME="${USER}_${CURRENT_TIMESTAMP}_gen"
      aws ${AWS_PROFILE_USE_CHECK[*]} ec2 import-key-pair --key-name ${KEY_NAME} --public-key-material fileb://"${HOME}/.ssh/id_rsa.pub" > "${TMP}/${AWS_EC2_KEYPAIRS}_${KEY_NAME}_imported_full.json" 2>"${LOG}/${AWS_EC2_KEYPAIRS}_${KEY_NAME}_imported.log"
      ERROR_CODE="$?"
      if [ ${ERROR_CODE} -eq 0 ]
      then
        KEY_FINGERPRINT=$(jq -r '.KeyFingerprint' "${TMP}/${AWS_EC2_KEYPAIRS}_${KEY_NAME}_imported_full.json")
        KEY_PAIR_ID=$(jq -r '.KeyPairId' "${TMP}/${AWS_EC2_KEYPAIRS}_${KEY_NAME}_imported_full.json")
        inf "          Imported key: ${BROWN}${KEY_PAIR_ID}"
      else
        error "          Key cannot be imported, exiting"
        debug "            LOG FILE: ${YELLOW}${LOG}/${AWS_EC2_KEYPAIRS}_${KEY_NAME}_imported.log"
        error "              $(cat "${LOG}/${AWS_EC2_KEYPAIRS}_${KEY_NAME}_imported.log")"
        failed
      fi
      aws ${AWS_PROFILE_USE_CHECK[*]} ec2 describe-key-pairs > "${TMP}/${AWS_EC2_KEYPAIRS}_full.json" 2>"${LOG}/${AWS_EC2_KEYPAIRS}.log" &
    else
      export KEY_NAME=$(jq -r --arg KeyFingerprint ${CURRENT_USER_FINGERPRINT} '.KeyPairs[] | select(.KeyFingerprint == $KeyFingerprint) | .KeyName' "${TMP}/${AWS_EC2_KEYPAIRS}_full.json")
      AMOUNT_OF_IDENTICAL_KEYS=$(echo "${KEY_NAME}" | wc -l)
      if [ ${AMOUNT_OF_IDENTICAL_KEYS} -gt 1 ]
      then
        inf "      Current user: ${YELLOW}${USER}${CYAN} exists in AWS EC2 with key name: ${BROWN}${KEY_NAME}${CYAN} (and in ${WINE}${AMOUNT_OF_IDENTICAL_KEYS}${CYAN} times)"
      else
        inf "      Current user: ${YELLOW}${USER}${CYAN} exists in AWS EC2 with key name: ${BROWN}${KEY_NAME}"
      fi
    fi
  else
    inf "  I cannot find private key of current user: ${YELLOW}${USER}${CYAN}, creating AWS key pairs"
    KEY_NAME="${USER}_${CURRENT_TIMESTAMP}_gen"
    aws ${AWS_PROFILE_USE_CHECK[*]} ec2 create-key-pair --key-name ${KEY_NAME} --query 'KeyMaterial' --output text > "${TMP}/${AWS_EC2_KEYPAIRS}_${KEY_NAME}-generated_id_rsa.key" 2>"${LOG}/${AWS_EC2_KEYPAIRS}_${KEY_NAME}-generated_id_rsa.log"
    aws ${AWS_PROFILE_USE_CHECK[*]} ec2 describe-key-pairs > "${TMP}/${AWS_EC2_KEYPAIRS}_full.json" 2>"${LOG}/${AWS_EC2_KEYPAIRS}.log"
    KEY_NAME="${USER}_${CURRENT_TIMESTAMP}_gen"
    KEY_FINGERPRINT=$(jq -r --arg key_name ${KEY_NAME} '.KeyPairs[] | select(.KeyName == $key_name) | .KeyFingerprint' "${TMP}/${AWS_EC2_KEYPAIRS}_full.json")
    KEY_PAIR_ID=$(jq -r --arg KeyFingerprint ${KEY_FINGERPRINT} '.KeyPairs[] | select(.KeyFingerprint == $KeyFingerprint) | .KeyPairId' "${TMP}/${AWS_EC2_KEYPAIRS}_full.json")
  fi
}

aws_key_removal()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}(1)KeyPairId"
    ERROR_CODE="1"
    failed
  else
    EC2_KEY_ID="${1}"
  fi
  inf "    Removing key: ${LIME}${KEY_PAIR_ID}"
  aws ${AWS_PROFILE_USE_CHECK[*]} ec2 delete-key-pair --key-pair-id "${KEY_PAIR_ID}" > "${LOG}/${AWS_EC2_KEYPAIRS}_${EC2_KEY_ID}_removal.log" 2>&1
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    inf "      Key ${LIME}${KEY_PAIR_ID}${CYAN} properly removed"
  else
    error "      Key ${LIME}${KEY_PAIR_ID}${CYAN} couldn't be removed properly, exiting"
    debug "        LOG FILE: ${YELLOW}${LOG}/${AWS_EC2_KEYPAIRS}_${EC2_KEY_ID}_removal.log"
    error "          $(cat "${LOG}/${AWS_EC2_KEYPAIRS}_${EC2_KEY_ID}_removal.log")"
    failed
  fi
}

aws_newest_ami()
{
  inf ""
  inf "${MAGENTA}Trying to figure it out the newest AMI:"
  if [ -s "${TMP}/${AWS_AMIS_DETAILS}_full.json" ]
  then
    AWS_AMI_IMAGE_AMOUNT=$(jq -r '.Images[].ImageId' "${TMP}/${AWS_AMIS_DETAILS}_full.json" | wc -l)
    LATEST_AMI_ID=$(jq -r '.Images[] | .CreationDate + " " + .ImageId' "${TMP}/${AWS_AMIS_DETAILS}_full.json" | sort | tail -n1 | awk '{print $2}')
    OLDEST_AMI_ID=$(jq -r '.Images[] | .CreationDate + " " + .ImageId' "${TMP}/${AWS_AMIS_DETAILS}_full.json" | sort | head -n1 | awk '{print $2}')
    inf "  The latest one seems to be this one: ${BROWN}${LATEST_AMI_ID}"
    IMAGE_STATE=$(jq -r --arg ImageId ${LATEST_AMI_ID} '.Images[] | select(.ImageId == $ImageId) | .State' "${TMP}/${AWS_AMIS_DETAILS}_full.json")
    if [[ ${IMAGE_STATE} == "available" ]]
    then
      AWS_AMI_ID="${LATEST_AMI_ID}"
      inf "    And it is available..."
    elif [[ ${IMAGE_STATE} == "failed"  ]]
    then
      error "    Image: ${BROWN}${LATEST_AMI_ID}${RED} is in a state: failed"
      AMI_FAILED_REASON=$(jq -r --arg ImageId ${LATEST_AMI_ID} '.Images[] | select(.ImageId == $ImageId) | .StateReason.Code' "${TMP}/${AWS_AMIS_DETAILS}_full.json")
      error "      Reason: ${WINE}${AMI_FAILED_REASON}"
      failed
    elif [[ ${IMAGE_STATE} == "pending"  ]]
    then
      warn "    Image: ${BROWN}${LATEST_AMI_ID}${WINE} is in status pending, waiting for state change"
      while [[ $(aws ${AWS_PROFILE_USE_CHECK[*]} ec2 describe-images ${AWS_PROFILE_USE_CHECK[*]} --image-ids  ${LATEST_AMI_ID} | jq -r '.Images[].State') == "available" ]]
      do
        for NUMBER in {1..100}
        do
          sleep 0.15
          ProgressBar ${NUMBER} 100
        done
        printf '\n'
      done
    fi
    if [ ${AWS_AMI_IMAGE_AMOUNT} -ge 3 ]
    then
      debug "      And the oldest seems to be this one: ${BROWN}${OLDEST_AMI_ID}"
    fi
  else
    error "  There is no AMI(s), exitting"
    #ToDo: picking up examples AMI: 
    failed
  fi
}

aws_list-roles()
{
  inf ""
  inf "${MAGENTA}IAM roles:"
  aws ${AWS_PROFILE_USE_CHECK[*]} iam list-roles > "${TMP}/${AWS_ROLES}_full.json" 2>"${LOG}/${AWS_ROLES}.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    ROLES_CHECK=$(jq -r --arg aws_default_name ${AWS_DEFAULT_NAME} '.Roles[] | select(.Arn | contains("aws-service-role") | not) | select(.Arn | contains($aws_default_name) | not) | .Arn' "${TMP}/${AWS_ROLES}_full.json" | head -n1) 
    if [ -z ${ROLES_CHECK} ]
    then
      warn "  There is no role(s)"
    else
      jq -r --arg aws_default_name ${AWS_DEFAULT_NAME} '.Roles[] | select(.Arn | contains("aws-service-role") | not) | select(.Arn | contains($aws_default_name) | not)' "${TMP}/${AWS_ROLES}_full.json" > "${TMP}/${AWS_ROLES}_${AWS_NAMES_PREFIX}_full.json" 2>"${LOG}/${AWS_ROLES}_${AWS_NAMES_PREFIX}.log"
      for AWS_IAM_ROLE_NAME in $(jq -r '.RoleName' "${TMP}/${AWS_ROLES}_${AWS_NAMES_PREFIX}_full.json")
      do
        AWS_IAM_ROLE_ARN="$(jq -r --arg aws_iam_role_name ${AWS_IAM_ROLE_NAME} '.Roles[] | select(.RoleName == $aws_iam_role_name) | .Arn' "${TMP}/${AWS_ROLES}_full.json")"
        AWS_IAM_ROLE_ID=$(jq -r --arg aws_iam_role_name ${AWS_IAM_ROLE_NAME} '.Roles[] | select(.RoleName == $aws_iam_role_name) | .RoleId' "${TMP}/${AWS_ROLES}_full.json")
        inf "  Role: ${YELLOW}${AWS_IAM_ROLE_NAME}${CYAN}, with ARN: ${LIME}${AWS_IAM_ROLE_ARN}${CYAN} exists"
        AWS_IAM_POLICY_NAME_CHECK=$(aws_list-attached-role-policies ${AWS_IAM_ROLE_NAME} && jq -r '.AttachedPolicies[].PolicyName' "${TMP}/${AWS_POLICIES_ATTACHED_ROLE}_${AWS_IAM_ROLE_NAME}_full.json" | head -n1)
        if [ -z ${AWS_IAM_POLICY_NAME_CHECK} ]
        then
          inf "    and there is no policy attached to it"
          INSTANCE_PROFILE_ROLE_NAME=$(aws_list-instance-profiles-for-role "${AWS_IAM_ROLE_NAME}" && jq -r '.InstanceProfiles[].InstanceProfileName' "${TMP}/${AWS_INSTANCE_PROFILES}_${AWS_IAM_ROLE_NAME}_full.json")
          if [ ! -z ${INSTANCE_PROFILE_ROLE_NAME} ]
          then
            inf "      and role: ${YELLOW}${INSTANCE_PROFILE_ROLE_NAME}${CYAN} is attached to instance profile: ${DARK_GREEN}${INSTANCE_PROFILE_ROLE_NAME}"
            if [[ ${CLEANING} == yes ]] && [[ ${XTRA_CLEANING} == yes ]] && [[ ${AWS_ZONE} == "N" ]]
            then
              aws_removing_role_from_instance_profile "${AWS_IAM_ROLE_NAME}" "${INSTANCE_PROFILE_ROLE_NAME}"
              aws_role_removal "${AWS_IAM_ROLE_NAME}"
              aws_instance-profile_removal "${INSTANCE_PROFILE_ROLE_NAME}"
            fi
          else
	        inf "      and it is not attached to any instance profile"
            if [[ ${CLEANING} == yes ]] && [[ ${XTRA_CLEANING} == yes ]]
            then
              aws_role_removal "${AWS_IAM_ROLE_NAME}"
            fi
          fi
        else
          for AWS_IAM_POLICY_NAME in $(jq -r '.AttachedPolicies[].PolicyName' "${TMP}/${AWS_POLICIES_ATTACHED_ROLE}_${AWS_IAM_ROLE_NAME}_full.json")
          do
            AWS_IAM_ROLE_POLICY_ARN=$(aws ${AWS_PROFILE_USE_CHECK[*]} iam list-policies | jq -r --arg policy_name ${AWS_IAM_POLICY_NAME} '.Policies[] | select(.PolicyName == $policy_name) | .Arn')
            inf "    and there is a policy attached to it: ${YELLOW}${AWS_IAM_POLICY_NAME}${CYAN}, with ARN: ${LIME}${AWS_IAM_ROLE_POLICY_ARN}"
            if [[ ${CLEANING} == yes ]] && [[ ${XTRA_CLEANING} == yes ]] && [[ ${AWS_ZONE} == "N" ]]
            then
              aws_policy_removal "${AWS_IAM_ROLE_POLICY_ARN}"
            fi
            INSTANCE_PROFILE_ROLE_NAME=$(aws_list-instance-profiles-for-role "${AWS_IAM_ROLE_NAME}" && jq -r '.InstanceProfiles[].InstanceProfileName' "${TMP}/${AWS_INSTANCE_PROFILES}_${AWS_IAM_ROLE_NAME}_full.json")
            if [ ! -z ${INSTANCE_PROFILE_ROLE_NAME} ]
            then
              inf "      and role: ${YELLOW}${INSTANCE_PROFILE_ROLE_NAME}${CYAN} is attached to instance profile: ${DARK_GREEN}${INSTANCE_PROFILE_ROLE_NAME}"
              if [[ ${CLEANING} == yes ]] && [[ ${XTRA_CLEANING} == yes ]] && [[ ${AWS_ZONE} == "N" ]]
              then
                aws_removing_role_from_instance_profile "${AWS_IAM_ROLE_NAME}" "${INSTANCE_PROFILE_ROLE_NAME}"
                aws_role_removal "${AWS_IAM_ROLE_NAME}"
                aws_instance-profile_removal "${INSTANCE_PROFILE_ROLE_NAME}"
              fi
            else
	          inf "      and it is not attached to any instance profile"
              if [[ ${CLEANING} == yes ]] && [[ ${XTRA_CLEANING} == yes ]] && [[ ${AWS_ZONE} == "N" ]]
              then
                aws_role_removal "${AWS_IAM_ROLE_NAME}"
              fi
            fi
          done
        fi
      done
    fi
  else
    error "  Roles couldn't be collected properly, exiting"
    debug "    LOG FILE: ${YELLOW}${LOG}/${AWS_ROLES}.log"
    error "    $(cat "${LOG}/${AWS_ROLES}.log")"
    failed
  fi
}

aws_list-profiles()
{
  inf ""
  inf "${MAGENTA}EC2 instance profiles:"
  aws ${AWS_PROFILE_USE_CHECK[*]} iam list-instance-profiles > "${TMP}/${AWS_INSTANCE_PROFILES}_full.json" 2>"${LOG}/${AWS_INSTANCE_PROFILES}.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    INSTANCE_PROFILES_CHECK=$(jq -r '.InstanceProfiles[].Arn' "${TMP}/${AWS_INSTANCE_PROFILES}_full.json" | head -n1)
    if [ -z ${INSTANCE_PROFILES_CHECK} ]
    then
      warn "  There is no instance profile(s)"
    else
      for INSTANCE_PROFILE_NAME in $(jq -r '.InstanceProfiles[].InstanceProfileName' "${TMP}/${AWS_INSTANCE_PROFILES}_full.json")
      do
        inf "  profile: ${YELLOW}${INSTANCE_PROFILE_NAME}${CYAN} exists"
        INSTANCE_PROFILE_ROLE_NAME=$(aws ${AWS_PROFILE_USE_CHECK[*]} iam get-instance-profile --instance-profile-name ${INSTANCE_PROFILE_NAME} | jq -r '.InstanceProfile.Roles[].RoleName')
        if [ ! -z ${INSTANCE_PROFILE_ROLE_NAME} ]
        then
          for ROLE_NAME in ${INSTANCE_PROFILE_ROLE_NAME}
          do
            inf "    Role: ${YELLOW}${ROLE_NAME}${CYAN} is attached to instance profile: ${DARK_GREEN}${INSTANCE_PROFILE_NAME}"
            AWS_IAM_POLICY_NAME=$(aws_list-attached-role-policies ${ROLE_NAME} && jq -r '.AttachedPolicies[].PolicyName' "${TMP}/${AWS_POLICIES_ATTACHED_ROLE}_${ROLE_NAME}_full.json")
            if [ -z $(head -n1 <(echo ${AWS_IAM_POLICY_NAME})) ]
            then
              inf "      And role: ${YELLOW}${ROLE_NAME}${CYAN} has no policy attached"
              if [[ ${CLEANING} == yes ]] && [[ ${XTRA_CLEANING} == yes ]] && [[ ${AWS_ZONE} == "N" ]]
              then
                aws_removing_role_from_instance_profile "${ROLE_NAME}" "${INSTANCE_PROFILE_NAME}"
                aws_role_removal "${ROLE_NAME}"
              fi
            else
              inf "      Role: ${YELLOW}${ROLE_NAME}${CYAN} has policy:"
              for POLICY_NAME in $(jq -r '.AttachedPolicies[].PolicyName' "${TMP}/${AWS_POLICIES_ATTACHED_ROLE}_${ROLE_NAME}_full.json")
              do
                inf "        ${DARK_GREEN}${POLICY_NAME}${CYAN} attached to it"
                if [[ ${CLEANING} == yes ]] && [[ ${XTRA_CLEANING} == yes ]] && [[ ${AWS_ZONE} == "N" ]]
                then
                  POLICY_ARN=$(jq -r '.AttachedPolicies[].PolicyName' "${TMP}/${AWS_POLICIES_ATTACHED_ROLE}_${ROLE_NAME}_full.json")
                  aws_policy_removal "${POLICY_ARN}"
                  aws_removing_role_from_instance_profile "${ROLE_NAME}" "${INSTANCE_PROFILE_NAME}"
                  aws_role_removal "${ROLE_NAME}"
                fi
              done
            fi
          done
          if [[ ${CLEANING} == yes ]] && [[ ${XTRA_CLEANING} == yes ]] && [[ ${AWS_ZONE} == "N" ]]
          then
            aws_instance-profile_removal "${INSTANCE_PROFILE_NAME}"
          fi
        else
          inf "    and there is no role attached to it"
          if [[ ${CLEANING} == yes ]] && [[ ${XTRA_CLEANING} == yes ]] && [[ ${AWS_ZONE} == "N" ]]
          then
            aws_instance-profile_removal "${INSTANCE_PROFILE_NAME}"
          fi
        fi
      done
    fi
  else
    error "  Instance profiles couldn't be collected properly, exiting"
    debug "    LOG FILE: ${YELLOW}${LOG}/${AWS_INSTANCE_PROFILES}.log"
    error "      $(cat "${LOG}/${AWS_INSTANCE_PROFILES}.log")"
    failed
  fi
}

aws_list-securitygroups()
{
  inf ""
  inf "${MAGENTA}EC2 security groups:"
  aws ${AWS_PROFILE_USE_CHECK[*]} ec2 describe-security-groups > "${TMP}/${AWS_SECURITY_GROUPS}_full.json" 2>"${LOG}/${AWS_SECURITY_GROUPS}.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    SECURITY_GROUPS_CHECK=$(jq -r '.SecurityGroups[].Arn' "${TMP}/${AWS_SECURITY_GROUPS}_full.json" | head -n1)
    if [ -z ${SECURITY_GROUPS_CHECK} ]
    then
      warn "  There is no security group(s)"
    else
      for SECURITY_GROUP_ID in $(jq -r '.SecurityGroups[].GroupId' "${TMP}/${AWS_SECURITY_GROUPS}_full.json")
      do
        SECURITY_GROUP_NAME=$(jq -r --arg security_group_id ${SECURITY_GROUP_ID} '.SecurityGroups[] | select(.GroupId == $security_group_id) | .GroupName' "${TMP}/${AWS_SECURITY_GROUPS}_full.json")
        inf "  Security group: ${BLUE}${SECURITY_GROUP_NAME}${CYAN}, with Id: ${LIME}${SECURITY_GROUP_ID}"
        if [[ ${CLEANING} == yes ]] && [[ ${SECURITY_GROUP_NAME} != *"_lambda_ec2-"* ]]  && [[ ${AWS_ZONE} == "N" ]]
        then
          aws_ec2_security_group_delete ${SECURITY_GROUP_ID}
        elif [[ ${CLEANING} == yes ]] && [[ ${XTRA_CLEANING} == yes ]] && [[ ${AWS_ZONE} == "N" ]]
        then
          aws_ec2_security_group_delete ${SECURITY_GROUP_ID}
        fi
      done
    fi
  else
    error "  Security groups couldn't be collected properly, exiting"
    debug "    LOG FILE: ${YELLOW}${LOG}/${AWS_SECURITY_GROUPS}.log"
    error "      $(cat "${LOG}/${AWS_SECURITY_GROUPS}.log")"
    failed
  fi
}

aws_AMI_create()
{
  if [ $# -ne 2 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}(1)InstanceId, (2)AmiName"
    ERROR_CODE="1"
    failed
  else
    EC2_INSTANCE_ID="${1}"
    AMI_NAME=${2}
  fi
  aws ${AWS_PROFILE_USE_CHECK[*]} ec2 create-image --instance-id ${EC2_INSTANCE_ID} --name "${AMI_NAME}_${CURRENT_TIMESTAMP}" --description "${AWS_NAMES_PREFIX} AMI" > "${TMP}/${AWS_AMIS_DETAILS}_${EC2_INSTANCE_ID}_full.json"
  #ToDo: slack_notification (1)slack channel, (2) slack notification title, (3) slack notificatio text, (4)icon_emoji, (5) slack notification color, (6) footer url, (7) footer link
  AMI_ID=$(jq -r 'ImageId' "${TMP}/${AWS_AMIS_DETAILS}_${EC2_INSTANCE_ID}_full.json")
  if [[ ${AWS_OWNER_ID} == "623623120519" ]]
  then
    aws ${AWS_PROFILE_USE_CHECK[*]} ec2 modify-image-attribute --image-id ${AMI_ID} --launch-permission "Add=[{UserId=365117780834}]"
  elif [[ ${AWS_OWNER_ID} == "365117780834" ]]
  then
    aws ${AWS_PROFILE_USE_CHECK[*]} ec2 modify-image-attribute --image-id ${AMI_ID} --launch-permission "Add=[{UserId=623623120519}]"
  fi
}

aws_instance_removal()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}instance-id"
    ERROR_CODE="1"
    failed
  else
    AWS_INSTANCE_ID="${1}"
  fi
  inf "    ${WINE}Terminating instance: ${YELLOW}${AWS_INSTANCE_ID}"
  aws ${AWS_PROFILE_USE_CHECK[*]} ec2 terminate-instances --instance-id ${AWS_INSTANCE_ID} > "${TMP}/${AWS_INSTANCES_DETAILS}_${AWS_INSTANCE_ID}_termination.json" 2>"${LOG}/${AWS_INSTANCES_DETAILS}_${AWS_INSTANCE_ID}_termination.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    inf "      ${WINE}instance ${YELLOW}${AWS_INSTANCE_ID}${WINE} terminated properly."
    SLACK_TERMINATE_INSTANCE="
     {\\\"channel\\\": \\\"${SLACK_CHANNEL_AWS}\\\"
      , \\\"username\\\": \\\"${USER}\\\"
      , \\\"icon_emoji\\\": \\\":bomb:\\\"
      , \\\"attachments\\\":
        [
          {
            \\\"fallback\\\": \\\"EC2 instance: ${AWS_INSTANCE_ID} was terminated properly\\\",
            \\\"title\\\": \\\"Termination EC2 instance: ${AWS_INSTANCE_ID}\\\",
            \\\"title_link\\\": \\\"${AWS_LOGIN_URL}\\\",
            \\\"footer\\\": \\\"<${AWS_LOGIN_URL}|AWS log in:>\\\",
            \\\"footer_icon\\\": \\\"https://github.com/quintessence/slack-icons/blob/master/images/amazon-web-services-slack-icon.png\\\"
          }
        ]
        , \\\"token\\\": \\\"${SLACK_TOKEN}\\\"
      }"
    echo "curl ${SLACK_PROXY_CONTROL[*]} -v -X POST --data \"${SLACK_TERMINATE_INSTANCE}\" ${SLACK_WEB_HOOK}" > "${TMP}/${AWS_INSTANCES_DETAILS}_${AWS_INSTANCE_ID}_termination_slack.in"
    source "${TMP}/${AWS_INSTANCES_DETAILS}_${AWS_INSTANCE_ID}_termination_slack.in" > "${LOG}/${AWS_INSTANCES_DETAILS}_${AWS_INSTANCE_ID}_termination_slack.log" 2>&1
  else
    failed
  fi
}

aws_instance_stop()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}instance-id"
    ERROR_CODE="1"
    failed
  else
    AWS_INSTANCE_ID="${1}"
  fi
  aws ${AWS_PROFILE_USE_CHECK[*]} ec2 stop-instances --instance-id ${AWS_INSTANCE_ID} > "${TMP}/${AWS_INSTANCES_DETAILS}_${AWS_INSTANCE_ID}_stop.json" 2>"${LOG}/${AWS_INSTANCES_DETAILS}_${AWS_INSTANCE_ID}_stop.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    inf "      ${WINE}instance ${YELLOW}${AWS_INSTANCE_ID}${WINE} stopped properly."
  else
    error "      instance ${YELLOW}${AWS_INSTANCE_ID}${RED} cannot be stopped"
    debug "        LOG FILE: ${YELLOW}${LOG}/${AWS_INSTANCES_DETAILS}_${AWS_INSTANCE_ID}_stop.log"
    error "          $(cat "${LOG}/${AWS_INSTANCES_DETAILS}_${AWS_INSTANCE_ID}_stop.log")"
    failed
  fi
}

aws_vol_state_check()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}volume-id"
    ERROR_CODE="1"
    failed
  else
    AWS_VOLUME_ID="${1}"
  fi
  aws ${AWS_PROFILE_USE_CHECK[*]} ec2 describe-volumes --volume-ids ${AWS_VOLUME_ID} > "${TMP}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}_full.json" 2>"${LOG}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    if grep -q "volume ${AWS_VOLUME_ID} does not exist" "${TMP}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}_full.json" 
    then
      warn "  Volume ${YELLOW}${AWS_VOLUME_ID}${WINE} has not existed already"
    else
      error "  Cannot check state of the volume: ${YELLOW}${AWS_VOLUME_ID}"
      debug "    LOG FILE: ${YELLOW}${LOG}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}.log"
      error "      $(cat "${LOG}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}.log")"
    fi
  else
    VOLUME_STATE_ATTACHED=$(jq -r '.Volumes[].Attachments[].State' "${TMP}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}_full.json")
  fi
}

aws_vol_removal()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}volume-id"
    ERROR_CODE="1"
    failed
  else
    AWS_VOLUME_ID="${1}"
  fi
  aws ${AWS_PROFILE_USE_CHECK[*]} ec2 describe-volumes --volume-ids ${AWS_VOLUME_ID} > "${TMP}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}_full.json" 2>"${LOG}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    error "  Cannot collect volume ${YELLOW}${RED}${AWS_VOLUME_ID} information"
    debug "    LOG FILE: ${YELLOW}${LOG}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}.log"
    error "      $(cat "${LOG}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}.log")"
    failed
  fi
  DELETE_ON_TERMINATION=$(jq -r '.Volumes[].Attachments[].DeleteOnTermination' "${TMP}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}_full.json")
  AWS_VOLUME_INSTANCE_ID=$(jq -r '.Volumes[].Attachments[].InstanceId' "${TMP}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}_full.json")
  if [ -z ${DELETE_ON_TERMINATION} ] || [[ ${DELETE_ON_TERMINATION} == "false" ]]
  then
    inf   "      ${WINE}Removing not in-use volume: ${YELLOW}${AWS_VOLUME_ID}${WINE}"
    inf   "        Waiting for volume ${YELLOW}${AWS_VOLUME_ID}${CYAN} to be detached"
    while [ ! -z $(aws_vol_state_check ${AWS_VOLUME_ID} && echo ${VOLUME_STATE_ATTACHED}) ]
    do
      for NUMBER in {1..100}
      do
        sleep 0.15
        ProgressBar ${NUMBER} 100
      done
      printf '\n'
    done
    aws ${AWS_PROFILE_USE_CHECK[*]} ec2 delete-volume --volume-id ${AWS_VOLUME_ID} > "${TMP}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}_termination.json" 2>"${LOG}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}_termination.log"
    ERROR_CODE="$?"
    if [ ${ERROR_CODE} -eq 0 ]
    then
      inf "          ${WINE}volume: ${YELLOW}${AWS_VOLUME_ID}${WINE} removed properly"
      SLACK_REMOVE_VOLUME="
        {\\\"channel\\\": \\\"${SLACK_CHANNEL_AWS}\\\"
          , \\\"username\\\": \\\"${USER}\\\"
          , \\\"icon_emoji\\\": \\\":file_folder:\\\"
          , \\\"attachments\\\":
          [
            {
              \\\"fallback\\\": \\\"AWS unused volume: ${AWS_VOLUME_ID} has just been removed\\\",
              \\\"title\\\": \\\"Removal of AWS unused volume: ${AWS_VOLUME_ID}\\\",
              \\\"title_link\\\": \\\"${AWS_LOGIN_URL}\\\",
              \\\"footer\\\": \\\"<${AWS_LOGIN_URL}|AWS log in:>\\\",
              \\\"footer_icon\\\": \\\"https://github.com/quintessence/slack-icons/blob/master/images/amazon-web-services-slack-icon.png\\\"
            }
          ]
          , \\\"token\\\": \\\"${SLACK_TOKEN}\\\"
        }"
      echo "curl ${SLACK_PROXY_CONTROL[*]} -v -X POST --data \"${SLACK_REMOVE_VOLUME}\" ${SLACK_WEB_HOOK}" > "${TMP}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}_termination_slack.in"
      source "${TMP}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}_termination_slack.in" > "${LOG}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}_termination_slack.log" 2>&1
    else
      error "          volume: ${YELLOW}${AWS_VOLUME_ID}${RED} cannot be removed"
      debug "            LOG FILE: ${YELLOW}${LOG}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}_termination.log"
      error "            $(cat "${LOG}/${AWS_VOLS_DETAILS}_${AWS_VOLUME_ID}_termination.log")"
      failed
    fi
  elif [[ ${DELETE_ON_TERMINATION} == "true" ]]
  then
    inf "      ${WINE}volume: ${YELLOW}${AWS_VOL_ID}${WINE} has attached to the instance ${YELLOW}${AWS_VOLUME_INSTANCE_ID}${WINE} with DeleteOnTerminate flag set"
  fi
}

aws_snapshot_removal()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}snapshot-id"
    ERROR_CODE="1"
    failed
  else
    AWS_SNAPSHOT_ID="${1}"
  fi
  aws ${AWS_PROFILE_USE_CHECK[*]} ec2 describe-snapshots --snapshot-ids ${AWS_SNAPSHOT_ID} > "${TMP}/${AWS_SNAPS_DETAILS}_${AWS_SNAPSHOT_ID}_full.json" 2>"${LOG}/${AWS_SNAPS_DETAILS}_${AWS_SNAPSHOT_ID}.log"
  AWS_SNAPSHOT_ID_CHECK=$(jq -r '.Snapshots[].SnapshotId' "${TMP}/${AWS_SNAPS_DETAILS}_${AWS_SNAPSHOT_ID}_full.json")
  if [ ! -z ${AWS_SNAPSHOT_ID_CHECK} ]
  then
    if [ -s "${TMP}/${AWS_AMIS_DETAILS}_full.json" ]
    then
      AMI_ID_SNAPSHOT=$(jq -r --arg snap_id "${AWS_SNAPSHOT_ID}" '.Images[] | select(.BlockDeviceMappings[].Ebs.SnapshotId == $snap_id) | .ImageId' "${TMP}/${AWS_AMIS_DETAILS}_full.json")
      if [ -z ${AMI_ID_SNAPSHOT} ]
      then
        inf   "    ${WINE}Removing not in-use snapshot (${YELLOW}${AWS_SNAPSHOT_ID}${WINE}):"
        aws ${AWS_PROFILE_USE_CHECK[*]} ec2 delete-snapshot --snapshot-id ${AWS_SNAPSHOT_ID} > "${TMP}/${AWS_SNAPS_DETAILS}_${AWS_SNAPSHOT_ID}_termination.json" 2>"${LOG}/${AWS_SNAPS_DETAILS}_${AWS_SNAPSHOT_ID}_termination.log"
        ERROR_CODE="$?"
        if [ ${ERROR_CODE} -eq 0 ]
        then
          inf "        ${WINE}Snapshot: ${YELLOW}${AWS_SNAPSHOT_ID}${WINE} removed properly"
          SLACK_REMOVE_VOLUME="
            {\\\"channel\\\": \\\"${SLACK_CHANNEL_AWS}\\\"
              , \\\"username\\\": \\\"${USER}\\\"
              , \\\"icon_emoji\\\": \\\":file_folder:\\\"
              , \\\"attachments\\\":
              [
                {
                  \\\"fallback\\\": \\\"AWS unused snapshot: ${AWS_SNAPSHOT_ID} has just been removed\\\",
                  \\\"title\\\": \\\"Removal of AWS unused snapshot: ${AWS_SNAPSHOT_ID}\\\",
                  \\\"title_link\\\": \\\"${AWS_LOGIN_URL}\\\",
                  \\\"footer\\\": \\\"<${AWS_LOGIN_URL}|AWS log in:>\\\",
                  \\\"footer_icon\\\": \\\"https://github.com/quintessence/slack-icons/blob/master/images/amazon-web-services-slack-icon.png\\\"
                }
              ]
              , \\\"token\\\": \\\"${SLACK_TOKEN}\\\"
            }"
          echo "curl ${SLACK_PROXY_CONTROL[*]} -v -X POST --data \"${SLACK_REMOVE_VOLUME}\" ${SLACK_WEB_HOOK}" > "${TMP}/${AWS_SNAPS_DETAILS}_${AWS_SNAPSHOT_ID}_termination_slack.in"
          source "${TMP}/${AWS_SNAPS_DETAILS}_${AWS_SNAPSHOT_ID}_termination_slack.in" > "${LOG}/${AWS_SNAPS_DETAILS}_${AWS_SNAPSHOT_ID}_termination_slack.log" 2>&1
        else
          error "      Snapshot: ${YELLOW}${AWS_SNAPSHOT_ID}${RED} cannot be removed"
          debug "        LOG FILE: ${YELLOW}${LOG}/${AWS_SNAPS_DETAILS}_${AWS_SNAPSHOT_ID}_termination.log"
          error "          $(cat "${LOG}/${AWS_SNAPS_DETAILS}_${AWS_SNAPSHOT_ID}_termination.log")"
          failed
        fi
      fi
    fi
  fi
}

aws_ec2_policy_create()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}policy-name"
    ERROR_CODE="1"
    failed
  else
    AWS_POLICY_NAME="${1}"
  fi
  inf "    Creating policy: ${DARK_GREEN}${AWS_POLICY_NAME}" 
  echo "{
          \"Version\": \"${AWS_POLICY_VERSION}\",
          \"Statement\": 
            [
              {
                \"Effect\": \"Allow\",
                \"Action\": 
                  [
                    \"s3:*\",
                    \"ec2:*\",
                    \"sns:*\",
                    \"cloudwatch:*\",
                    \"logs:*\",
                    \"lambda:*\",
                    \"cloudtrail:*\",
                    \"iam:*\",
                    \"ce:*\",
                    \"events:*\",
                    \"kms:*\"
                  ],
                \"Resource\": \"*\"
              }
            ]
        }" > "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}-def.json"
  aws ${AWS_PROFILE_USE_CHECK[*]} iam create-policy --policy-name "${AWS_POLICY_NAME}" --description "Full access from EC2 env to ANY internal S3 bucket, another instance, cloudwatch, iam and ce" --policy-document file://"${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}-def.json" > "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}_creation.json" 2>"${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_creation.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    inf "      Policy ${DARK_GREEN}${AWS_POLICY_NAME}${CYAN} created properly"
  else
    error "      Policy ${DARK_GREEN}${AWS_POLICY_NAME}${RED} creation failed, exiting.."
    debug "        LOG FILE: ${YELLOW}${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_creation.log"
    error "          $(cat "${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_creation.log")"
    failed
  fi
}

aws_lambda_policy_create()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}policy-name"
    ERROR_CODE="1"
    failed
  else
    AWS_POLICY_NAME="${1}"
  fi
  inf "    Creating policy: ${DARK_GREEN}${AWS_POLICY_NAME}"
  echo "{
          \"Version\": \"${AWS_POLICY_VERSION}\",
          \"Statement\":
            [
              {
                \"Effect\": \"Allow\",
                \"Action\":
                  [
                    \"logs:CreateLogGroup\",
                    \"logs:CreateLogStream\",
                    \"logs:PutLogEvents\"
                  ],
                \"Resource\": \"arn:aws:logs:*:*:*\"
              },
              {
                \"Effect\": \"Allow\",
                \"Action\":
                  [
                    \"iam:PassRole\"
              ],
                \"Resource\": \"*\"
              },
              {
                \"Effect\": \"Allow\",
                \"Action\":
                  [
                    \"ec2:*\",
                    \"sns:*\"
              ],
                \"Resource\": \"*\"
              }
            ]
        }" > "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}-def.json"
  aws ${AWS_PROFILE_USE_CHECK[*]} iam create-policy --policy-name "${AWS_POLICY_NAME}" --description "Full access from Lambda to EC2" --policy-document file://"${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}-def.json" > "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}_creation.json" 2>"${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_creation.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    inf "      Lambda policy ${DARK_GREEN}${AWS_POLICY_NAME}${CYAN} created properly"
  else
    error "      Lambda policy ${DARK_GREEN}${AWS_POLICY_NAME}${RED} creation failed, exiting.."
    debug "        LOG FILE: ${YELLOW}${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_creation.log"
    error "          $(cat "${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_creation.log")"
    failed
  fi
}

lambda_function_deployment()
{
  if [ $# -ne 2 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs two parameters: ${YELLOW}(1)handler_name, (2)lambda_name"
    ERROR_CODE="1"
    failed
  else
    AWS_LAMBDA_FUNCTION_NAME="${1}"
    AWS_LAMBDA_HANDLER_NAME="${2}"
  fi
  LAMBDA_FUNCTION_ARN=$(jq -r --arg aws_default_name ${AWS_DEFAULT_NAME} --arg ec2_lambda_function ${AWS_LAMBDA_FUNCTION_NAME} '.Functions[] | select(.FunctionName | startswith($aws_default_name) | not) | select(.FunctionName == $ec2_lambda_function) | .FunctionArn' "${TMP}/${AWS_LAMBDA_FUNCTIONS}_full.json")
  if [ ! -z ${LAMBDA_FUNCTION_ARN} ]
  then
    warn "  Lambda function: ${BLUE}${AWS_LAMBDA_FUNCTION_NAME}${WINE} already exists"
    EC2_LAMBDA_SCRIPT_ARN=$(jq -r --arg aws_lambda_function_name ${AWS_LAMBDA_FUNCTION_NAME} '.Functions[] | select(.FunctionName == $aws_lambda_function_name) | .FunctionArn' "${TMP}/${AWS_LAMBDA_FUNCTIONS}_full.json")
  else
    inf "Preparing Lambda function: ${YELLOW}${AWS_LAMBDA_FUNCTION_NAME}"
    cat "${SCRIPTS_HOME}/lambda_functions/${LAMBDA_SCRIPT}" | envsubst > "${TMP}/${AWS_LAMBDA_FUNCTION_NAME}.py"
    if [[ ${ZIP_ON} == yes ]]
    then
      zip -j -q "${TMP}/${AWS_LAMBDA_FUNCTION_NAME}.zip" "${TMP}/${AWS_LAMBDA_FUNCTION_NAME}.py"
    elif [[ ${SP_ON} == yes ]]
    then
      7z a "${TMP}/${AWS_LAMBDA_FUNCTION_NAME}.zip" "${SCRIPTS_HOME}/${AWS_LAMBDA_FUNCTION_NAME}.py" > "${TMP}/${AWS_LAMBDA_FUNCTION_NAME}_compress.output" 2>"${LOG}/${AWS_LAMBDA_FUNCTION_NAME}_compress.log"
    fi
    NUMBER=0
    while [ ${NUMBER} -le 10 ]
    do
      sleep 1
      ProgressBar ${NUMBER} 10
      NUMBER=$(( ${NUMBER} + 1))
    done
    printf '\n'
    inf "  Deploying Lambda function: ${YELLOW}${AWS_LAMBDA_FUNCTION_NAME}"
    aws ${AWS_PROFILE_USE_CHECK[*]} lambda create-function --timeout 15 --function-name ${AWS_LAMBDA_FUNCTION_NAME} --zip-file fileb://"${TMP}/${AWS_LAMBDA_FUNCTION_NAME}.zip" --handler ${AWS_LAMBDA_HANDLER} --runtime python3.8 --role ${EC2_LAMBDA_ROLE_ARN} > "${TMP}/${AWS_LAMBDA_FUNCTIONS}_${AWS_LAMBDA_FUNCTION_NAME}_full.json" 2>"${LOG}/${AWS_LAMBDA_FUNCTIONS}_${AWS_LAMBDA_FUNCTION_NAME}.log"
    ERROR_CODE="$?"
    if [ ${ERROR_CODE} -ne 0 ]
    then
      error "    Lambda function: ${YELLOW}${AWS_LAMBDA_FUNCTION_NAME}${RED} cannot be deployed"
      debug "      LOG FILE: ${YELLOW}${LOG}/${AWS_LAMBDA_FUNCTIONS}_${AWS_LAMBDA_FUNCTION_NAME}.log"
      ENCODED_ERROR_MESSAGE=$(grep "\[ERROR\]" "${LOG}/${AWS_LAMBDA_FUNCTIONS}_${AWS_LAMBDA_FUNCTION_NAME}.log" | awk -F"failure message:" '{print $2}')
      DECODED_ERROR_MESSAGE=$(aws ${AWS_PROFILE_USE_CHECK[*]} sts decode-authorization-message --output text --encoded-message ${ENCODED_ERROR_MESSAGE} | jq -r)
      error "        ${DECODED_ERROR_MESSAGE}"
      failed
    else
      while [[ $(aws ${AWS_PROFILE_USE_CHECK[*]} lambda get-function --function-name ${AWS_LAMBDA_FUNCTION_NAME} | jq -r '.Configuration.State') == "Pending" ]]
      do
        for NUMBER in {1..100}
        do
          sleep 0.15
          aws ${AWS_PROFILE_USE_CHECK[*]} lambda get-function --function-name ${AWS_LAMBDA_FUNCTION_NAME} | jq -r '.Configuration.State'
          ProgressBar ${NUMBER} 100
        done
        printf '\n'
      done
      inf "    Lambda function: ${YELLOW}${AWS_LAMBDA_FUNCTION_NAME}${CYAN} deployed properly"
      EC2_LAMBDA_SCRIPT_ARN=$(jq -r '.FunctionArn' "${TMP}/${AWS_LAMBDA_FUNCTIONS}_${AWS_LAMBDA_FUNCTION_NAME}_full.json")
      debug "      Slack notification...."
      source "${SCRIPTS_HOME}/slack_notification_lambda"
    fi
  fi
}

aws_list-entities-for-policy()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}policy-arn"
    ERROR_CODE="1"
    failed
  else
    AWS_POLICY_ARN="${1}"
    AWS_POLICY_NAME=$(echo ${AWS_POLICY_ARN} | awk -F\: '{print $6}' | awk -F\/ '{print $NF}')
  fi
  aws ${AWS_PROFILE_USE_CHECK[*]} iam list-entities-for-policy --policy-arn "${AWS_POLICY_ARN}" > "${TMP}/${AWS_POLICY_ENTITIES}_${AWS_POLICY_NAME}_full.json" 2>"${LOG}/${AWS_POLICY_ENTITIES}_${AWS_POLICY_NAME}.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    error "  Policy ${DARK_GREEN}${AWS_POLICY_ARN}${RED} entities couldn't be collected, exiting.."
    debug "    LOG FILE: ${YELLOW}${LOG}/${AWS_POLICY_ENTITIES}_${AWS_POLICY_NAME}.log"
    error "      $(cat "${LOG}/${AWS_POLICY_ENTITIES}_${AWS_POLICY_NAME}.log")"
    failed
  fi
}

aws_policy_removal()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}policy-arn"
    ERROR_CODE="1"
    failed
  else
    AWS_POLICY_ARN="${1}"
    AWS_POLICY_NAME=$(aws ${AWS_PROFILE_USE_CHECK[*]} iam list-policies | jq -r --arg aws_policy_arn ${AWS_POLICY_ARN} '.Policies[] | select(.Arn == $aws_policy_arn) | .PolicyName')
  fi
  inf "      Removing policy: ${DARK_GREEN}${AWS_POLICY_NAME}"
  aws ${AWS_PROFILE_USE_CHECK[*]} iam delete-policy --policy-arn "${AWS_POLICY_ARN}"  > "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}_policy_deletion.json" 2>"${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_policy_deletion.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    if grep -q AccessDenied "${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_policy_deletion.log"
    then
      warn "        Policy: ${DARK_GREEN}${AWS_POLICY_NAME}${WINE} cannot be removed due to permissions..."
    elif grep -q DeleteConflict "${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_policy_deletion.log"
    then
      warn "        Policy: ${DARK_GREEN}${AWS_POLICY_NAME}${WINE} is still attached to entities:"
      aws  ${AWS_PROFILE_USE_CHECK[*]} iam list-entities-for-policy --policy-arn "${AWS_POLICY_ARN}" > "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}_entities.json" 2>&1
      if [ ! -z $(jq -r '.PolicyGroups[]' "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}_entities.json" | head -n1) ]
      then
        for POLICY_GROUP_ENT in $(jq -r '.PolicyGroups[].GroupName' "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}_entities.json")
        do
          warn "          Policy group: ${MAGENTA}${POLICY_GROUP_ENT}"
        done
      fi
      if [ ! -z $(jq -r '.PolicyUsers[]' "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}_entities.json" | head -n1) ]
      then
        for POLICY_USER_ENT in $(jq -r '.PolicyUsers[].UserName' "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}_entities.json")
        do
          warn "          Policy user: ${MAGENTA}${POLICY_USER_ENT}"
        done
      fi
      if [ ! -z $(jq -r '.PolicyRoles[]' "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}_entities.json" | head -n1) ]
      then
        for POLICY_ROLE_ENT in $(jq -r '.PolicyRoles[].RoleName' "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}_entities.json")
        do
          warn "          Policy role: ${MAGENTA}${POLICY_ROLE_ENT}"
        done
      fi
    else
      error "        policy: ${DARK_GREEN}${AWS_POLICY_NAME}${RED} cannot be removed, exiting"
      debug "          LOG FILE: ${YELLOW}${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_policy_deletion.log"
      error "            $(cat "${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_policy_deletion.log")"
      failed
    fi
  else
    inf "        policy: ${DARK_GREEN}${AWS_POLICY_NAME}${CYAN} removed properly"
  fi
}

aws_attaching_policy_to_role()
{
  if [ $# -ne 2 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs two parameters: ${YELLOW}(1)role-name, (2)policy-arn"
    ERROR_CODE="1"
    failed
  else
    AWS_ROLE_NAME=${1}
    AWS_POLICY_ARN="${2}"
  fi
  if [ -s "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}_creation.json" ]
  then
    AWS_POLICY_NAME=$(jq -r --arg prefixed_policy_arn "${AWS_POLICY_ARN}" '.Policy | select(.Arn == $prefixed_policy_arn) | .PolicyName' "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}_creation.json")
  else
    AWS_POLICY_NAME=$(jq -r --arg prefixed_policy_arn "${AWS_POLICY_ARN}" 'select(.Arn == $prefixed_policy_arn) | .PolicyName' "${TMP}/${AWS_POLICIES}_${AWS_NAMES_PREFIX}_full.json")
  fi
  inf "    Attaching policy: ${DARK_GREEN}${AWS_POLICY_NAME}${CYAN} to role: ${YELLOW}${AWS_ROLE_NAME}"
  aws ${AWS_PROFILE_USE_CHECK[*]} iam attach-role-policy --role-name ${AWS_ROLE_NAME} --policy-arn "${AWS_POLICY_ARN}" > "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}_attaching.json"  2>"${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_attaching.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    error "      Policy: ${DARK_GREEN}${AWS_POLICY_NAME}${RED} cannot be attached to role: ${YELLOW}${AWS_ROLE_NAME}${RED}, exiting"
    debug "        LOG FILE: ${YELLOW}${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_attaching.log"
    error "          $(cat "${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_attaching.log")"
    failed
  else
    inf "      Policy: ${DARK_GREEN}${AWS_POLICY_NAME}${CYAN} attached properly to role: ${YELLOW}${AWS_ROLE_NAME}"
  fi
}

aws_detaching_policy_from_role()
{
  if [ $# -ne 2 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs two parameters: ${YELLOW}(1)role-name, (2)policy-arn"
    ERROR_CODE="1"
    failed
  else
    AWS_IAM_ROLE_NAME=${1}
    AWS_POLICY_ARN="${2}"
    AWS_POLICY_NAME=$(aws ${AWS_PROFILE_USE_CHECK[*]} iam list-policies | jq -r --arg aws_policy_arn ${AWS_POLICY_ARN} '.Policies[] | select(.Arn == $aws_policy_arn) | .PolicyName')
  fi
  inf "      Detaching policy: ${DARK_GREEN}${AWS_POLICY_NAME}${CYAN} from role: ${YELLOW}${AWS_IAM_ROLE_NAME}${CYAN}..."
  aws ${AWS_PROFILE_USE_CHECK[*]} iam detach-role-policy --role-name ${AWS_IAM_ROLE_NAME} --policy-arn "${AWS_IAM_POLICY_ARN}" > "${TMP}/${AWS_POLICIES}_${AWS_POLICY_NAME}_detaching.json"  2>"${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_detaching.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    error "        Policy: ${DARK_GREEN}${AWS_POLICY_NAME}${RED} cannot be detached from role: ${YELLOW}${AWS_IAM_ROLE_NAME}${RED}, exiting"
    debug "          LOG FILE: ${YELLOW}${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_detaching.log"
    error "            $(cat "${LOG}/${AWS_POLICIES}_${AWS_POLICY_NAME}_detaching.log")"
    failed
  else
    inf "        Policy: ${DARK_GREEN}${AWS_POLICY_NAME}${CYAN} detached properly from role: ${YELLOW}${AWS_IAM_ROLE_NAME}"
  fi
}

aws_list-attached-role-policies()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}(1)role-name"
    ERROR_CODE="1"
    failed
  else
    AWS_IAM_ROLE_NAME=${1}
  fi
  aws ${AWS_PROFILE_USE_CHECK[*]} iam list-attached-role-policies --role-name ${AWS_IAM_ROLE_NAME} > "${TMP}/${AWS_POLICIES_ATTACHED_ROLE}_${AWS_IAM_ROLE_NAME}_full.json" 2>"${LOG}/${AWS_POLICIES_ATTACHED_ROLE}_${AWS_IAM_ROLE_NAME}.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    error "  Policies attached to role ${YELLOW}${AWS_IAM_ROLE_NAME}${RED} couldn't be collected, exiting.."
    debug "    LOG FILE: ${YELLOW}${LOG}/${AWS_POLICIES_ATTACHED_ROLE}_${AWS_IAM_ROLE_NAME}.log"
    error "      $(cat "${LOG}/${AWS_POLICIES_ATTACHED_ROLE}_${AWS_IAM_ROLE_NAME}.log")"
    failed
  fi
}

aws_list-instance-profiles-for-role()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}(1)role-name"
    ERROR_CODE="1"
    failed
  else
    AWS_IAM_ROLE_NAME=${1}
  fi
  aws ${AWS_PROFILE_USE_CHECK[*]} iam list-instance-profiles-for-role --role-name "${AWS_IAM_ROLE_NAME}" > "${TMP}/${AWS_INSTANCE_PROFILES}_${AWS_IAM_ROLE_NAME}_full.json" 2>"${LOG}/${AWS_INSTANCE_PROFILES}_${AWS_IAM_ROLE_NAME}.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    error "  Instance profiles attached to role ${YELLOW}${AWS_IAM_ROLE_NAME}${RED} couldn't be collected, exiting.."
    debug "    LOG FILE: ${YELLOW}${LOG}/${AWS_INSTANCE_PROFILES}_${AWS_IAM_ROLE_NAME}.log"
    error "      $(cat "${LOG}/${AWS_INSTANCE_PROFILES}_${AWS_IAM_ROLE_NAME}.log")"
    failed
  fi
}

aws_creating_instance_profile()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}(1)instance_profile-name"
    ERROR_CODE="1"
    failed
  else
    AWS_INSTANCE_PROFILE_NAME="${1}"
  fi
  inf "    Creating instance profile ${LIME}${AWS_INSTANCE_PROFILE_NAME}"
  aws ${AWS_PROFILE_USE_CHECK[*]} iam create-instance-profile --instance-profile-name "${AWS_INSTANCE_PROFILE_NAME}" > "${TMP}/${AWS_INSTANCE_PROFILES}_${AWS_INSTANCE_PROFILE_NAME}_creation.json" 2>"${LOG}/${AWS_INSTANCE_PROFILES}_${AWS_INSTANCE_PROFILE_NAME}_creation.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    AWS_EC2_INSTANCES_PROFILE_ID=$(jq -r '.InstanceProfile.InstanceProfileId' "${TMP}/${AWS_INSTANCE_PROFILES}_${AWS_INSTANCE_PROFILE_NAME}_creation.json")
    AWS_EC2_INSTANCES_PROFILE_ARN=$(jq -r '.InstanceProfile.Arn' "${TMP}/${AWS_INSTANCE_PROFILES}_${AWS_INSTANCE_PROFILE_NAME}_creation.json")
    inf "      Instance profile ${LIME}${AWS_INSTANCE_PROFILE_NAME}${CYAN} has just been created"
  else
    error "      Instance profile ${LIME}${AWS_INSTANCE_PROFILE_NAME}${RED} creation failed, exitting.."
    debug "        LOG FILE: ${YELLOW}${LOG}/${AWS_INSTANCE_PROFILES}_${AWS_INSTANCE_PROFILE_NAME}_creation.log"
    error "          $(cat "${LOG}/${AWS_INSTANCE_PROFILES}_${AWS_INSTANCE_PROFILE_NAME}_creation.log")"
    failed
  fi
}

aws_instance-profile_removal()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}instance-profile_name"
    ERROR_CODE="1"
    failed
  else
    AWS_INSTANCE_PROFILE_NAME="${1}"
  fi
  inf "        Removing instance_profile"
  aws ${AWS_PROFILE_USE_CHECK[*]} iam delete-instance-profile --instance-profile-name ${AWS_INSTANCE_PROFILE_NAME} > "${TMP}/${AWS_INSTANCE_PROFILES}_${AWS_INSTANCE_PROFILE_NAME}_deletion.json"  2>"${LOG}/${AWS_INSTANCE_PROFILES}_${AWS_INSTANCE_PROFILE_NAME}_deletion.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    error "         instance profile: ${DARK_GREEN}${AWS_INSTANCE_PROFILE_NAME}${RED} cannot be removed, exiting"
    debug "           LOG FILE: ${YELLOW}${LOG}/${AWS_INSTANCE_PROFILES}_${AWS_INSTANCE_PROFILE_NAME}_deletion.log"
    error "             $(cat "${LOG}/${AWS_INSTANCE_PROFILES}_${AWS_INSTANCE_PROFILE_NAME}_deletion.log")"
    failed
  else
    inf "          instance profile: ${DARK_GREEN}${AWS_INSTANCE_PROFILE_NAME}${CYAN} removed properly"
  fi
}

aws_removing_role_from_instance_profile()
{
  if [ $# -ne 2 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs two parameters: ${YELLOW}(1)role-name, (2)instance_profile-name"
    ERROR_CODE="1"
    failed
  else
    AWS_IAM_ROLE_NAME=${1}
    AWS_INSTANCE_PROFILE_NAME="${2}"
  fi
  inf "        Removing role: ${YELLOW}${AWS_IAM_ROLE_NAME}${CYAN} from instance profile: ${LIME}${AWS_INSTANCE_PROFILE_NAME}"
  aws ${AWS_PROFILE_USE_CHECK[*]} iam remove-role-from-instance-profile --instance-profile-name "${AWS_INSTANCE_PROFILE_NAME}" --role-name "${AWS_IAM_ROLE_NAME}" > "${TMP}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_role_from_instance-profile_deletion.json" 2>"${LOG}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_role_from_instance-profile_deletion.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    error "        Removing role: ${YELLOW}${AWS_IAM_ROLE_NAME}${RED} from instance profile: ${LIME}${AWS_INSTANCE_PROFILE_NAME}${RED} failed, exiting"
    debug "          LOG FILE: ${YELLOW}${LOG}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_role_from_instance-profile_deletion.log"
    error "            $(cat "${LOG}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_role_from_instance-profile_deletion.log")"
    failed
  else
    inf "          Removing role: ${YELLOW}${AWS_IAM_ROLE_NAME}${CYAN} from instance profile: ${LIME}${AWS_INSTANCE_PROFILE_NAME}${CYAN} succedeed"
  fi
}

aws_adding_role_to_instance_profile()
{
  if [ $# -ne 2 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs two parameters: ${YELLOW}(1)role_name, (2)instance_profile-name"
    ERROR_CODE="1"
    failed
  else
    ROLE_NAME=${1}
    EC2_INSTANCE_PROFILE_NAME="${2}"
  fi
  inf "    Adding role ${YELLOW}${ROLE_NAME}${CYAN} to instance profile ${LIME}${EC2_INSTANCE_PROFILE_NAME}"
  aws ${AWS_PROFILE_USE_CHECK[*]} iam add-role-to-instance-profile --role-name ${ROLE_NAME} --instance-profile-name "${EC2_INSTANCE_PROFILE_NAME}" > "${TMP}/${AWS_INSTANCE_PROFILES}_${EC2_INSTANCE_PROFILE_NAME}_role-to-instance_profile.json" 2>"${LOG}/${AWS_INSTANCE_PROFILES}_${EC2_INSTANCE_PROFILE_NAME}_role-to-instance_profile.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    inf "      Role ${YELLOW}${ROLE_NAME}${CYAN} has been added successfully to instance profile: ${LIME}${EC2_INSTANCE_PROFILE_NAME}"
  else
    error "      Role ${YELLOW}${ROLE_NAME}${RED} has not been added to instance profile: ${LIME}${EC2_INSTANCE_PROFILE_NAME}${RED}, exiting"
    debug "        LOG FILE: ${YELLOW}${LOG}/${AWS_INSTANCE_PROFILES}_${EC2_INSTANCE_PROFILE_NAME}_role-to-instance_profile.log"
    error "          $(cat "${LOG}/${AWS_INSTANCE_PROFILES}_${EC2_INSTANCE_PROFILE_NAME}_role-to-instance_profile.log")"
    failed
  fi
}

aws_role_create()
{
  if [ $# -ne 2 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs two parameters: ${YELLOW}role-name${RED}, ${YELLOW}service-name (ec2, lambda, s3)"
    ERROR_CODE="1"
    failed
  else
    AWS_IAM_ROLE_NAME=${1}
    AWS_SERVICE_NAME=${2}
  fi
  inf "    Creating role: ${YELLOW}${AWS_IAM_ROLE_NAME}"
  echo "{
    \"Version\": \"${AWS_POLICY_VERSION}\",
    \"Statement\":
    [
      {
        \"Effect\": \"Allow\",
        \"Principal\":
        {
          \"Service\": \"${AWS_SERVICE_NAME}.amazonaws.com\"
        },
        \"Action\": \"sts:AssumeRole\"
      }
    ]
  }" > "${TMP}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_role-def.json"
  if [ -z ${PERMISSIONS_BOUNDARY_ARN} ]
  then
    aws ${AWS_PROFILE_USE_CHECK[*]} iam create-role --role-name ${AWS_IAM_ROLE_NAME} --assume-role-policy-document file://"${TMP}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_role-def.json" > "${TMP}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_creation.json" 2>"${LOG}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_creation.log"
  else
    aws ${AWS_PROFILE_USE_CHECK[*]} iam create-role --permissions-boundary "${PERMISSIONS_BOUNDARY_ARN}" --role-name ${AWS_IAM_ROLE_NAME} --assume-role-policy-document file://"${TMP}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_role-def.json" > "${TMP}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_creation.json" 2>"${LOG}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_creation.log"
  fi
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    if [ -z ${PERMISSIONS_BOUNDARY_ARN} ]
    then
      inf "      Role ${YELLOW}${AWS_IAM_ROLE_NAME}${CYAN} has just been created"
    else
      inf "      Role ${YELLOW}${AWS_IAM_ROLE_NAME}${CYAN} with permissions boundary ARN: ${LIME}${PERMISSIONS_BOUNDARY_ARN}${CYAN} has just been created"
    fi
    AWS_IAM_ROLE_ARN="$(jq -r '.Role.Arn' "${TMP}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_creation.json")"
  else
    error "      Role ${YELLOW}${AWS_EC2_ROLE}${RED} creation failed, exiting.."
    debug "        LOG FILE: ${YELLOW}${LOG}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_creation.log"
    error "          $(cat "${LOG}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_creation.log")"
    failed
  fi
}

is_instance_up()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs two parameters: ${YELLOW}(1)InstanceId"
    ERROR_CODE="1"
    failed
  else
    AWS_EC2_INSTANCE_ID=${1}
  fi
  NUMBER=0
  while [ ${NUMBER} -le 8 ]
  do
    sleep 1
    ProgressBar ${NUMBER} 8
    NUMBER=$(( ${NUMBER} + 1))
  done
  printf '\n'
  if [ -s "${TMP}/${AWS_INSTANCES_DETAILS}_run_full.json" ]
  then
    AWS_EC2_INSTANCE_PRIVATE_IP=$(jq -r '.Instances[].PrivateIpAddress' "${TMP}/${AWS_INSTANCES_DETAILS}_run_full.json")
  elif [ -s "${TMP}/${AWS_INSTANCES_DETAILS}_${AWS_EC2_INSTANCE_ID}_full.json" ]
  then
    AWS_EC2_INSTANCE_PRIVATE_IP=$(jq -r '.Reservations[].Instances[].PrivateIpAddress' "${TMP}/${AWS_INSTANCES_DETAILS}_${AWS_EC2_INSTANCE_ID}_full.json")
  fi
  AWS_EC2_INSTANCE_PUBLIC_IP=$(aws ${AWS_PROFILE_USE_CHECK[*]} ec2 describe-instances --instance-ids ${AWS_EC2_INSTANCE_ID} | jq -r '.Reservations[].Instances[].PublicIpAddress')
  inf "    ${MAGENTA}Checking if instance: ${YELLOW}${AWS_EC2_INSTANCE_ID}${MAGENTA} is already up..."
  inf "      by: ${YELLOW}${DEPLOY_USER}${CYAN} user"
  if [ -z ${AWS_EC2_INSTANCE_PUBLIC_IP} ] || [[ ${AWS_EC2_INSTANCE_PUBLIC_IP} == "null" ]]
  then
    inf "        on private IP: ${LIME}${AWS_EC2_INSTANCE_PRIVATE_IP}"
    while ! $(timeout --preserve-status -s 9 -k 6 4 ssh -o "StrictHostKeyChecking no" ${DEPLOY_USER}@${AWS_EC2_INSTANCE_PRIVATE_IP} 'exit' >> "${LOG}/${AWS_INSTANCES_DETAILS}_ssh_testing.log" 2>&1 ) >> "${LOG}/${AWS_INSTANCES_DETAILS}_ssh_testing.log" 2>&1
    do
      for NUMBER in {1..100}
      do
        sleep 0.5
        ProgressBar ${NUMBER} 100
      done
      printf '\n'
    done
    inf "      Instance ${YELLOW}${AWS_EC2_INSTANCE_ID}${CYAN} is up"
  else
    inf "        on public IP: ${LIME}${AWS_EC2_INSTANCE_PUBLIC_IP}"
    while ! $(timeout --preserve-status -s 9 -k 6 4 ssh -o "StrictHostKeyChecking no" ${DEPLOY_USER}@${AWS_EC2_INSTANCE_PUBLIC_IP} 'exit' >> "${LOG}/${AWS_INSTANCES_DETAILS}_ssh_testing.log" 2>&1 ) >> "${LOG}/${AWS_INSTANCES_DETAILS}_ssh_testing.log" 2>&1
    do
      for NUMBER in {1..100}
      do
        sleep 0.5
        ProgressBar ${NUMBER} 100
      done
      printf '\n'
    done
    inf "      Instance ${YELLOW}${AWS_EC2_INSTANCE_ID}${CYAN} is up"
  fi
}

aws_role_removal()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}role-name"
    ERROR_CODE="1"
    failed
  else
    AWS_IAM_ROLE_NAME=${1}
  fi
  inf "        Removing role: ${YELLOW}${AWS_IAM_ROLE_NAME}"
  aws ${AWS_PROFILE_USE_CHECK[*]} iam delete-role --role-name ${AWS_IAM_ROLE_NAME} > "${TMP}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_role_deletion.json" 2>"${LOG}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_role_deletion.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    if grep -q AccessDenied "${LOG}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_role_deletion.log"
    then
      warn "          Role: ${YELLOW}${AWS_IAM_ROLE_NAME}${WINE} cannot be removed due to permissions..."
    elif grep -q DeleteConflict "${LOG}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_role_deletion.log"
    then
      aws ${AWS_PROFILE_USE_CHECK[*]} iam list-role-policies --role-name ${AWS_IAM_ROLE_NAME} > "${TMP}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_inline_policies.json" 2>&1
      warn "          Role: ${YELLOW}${AWS_IAM_ROLE_NAME}${WINE} is still attached to policy as entity:"
      for ROLE_ENTITY in $(jq -r '.PolicyNames[]' "${TMP}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_inline_policies.json")
      do
        warn "            To following inline/managed policy: ${DARK_GREEN}${ROLE_ENTITY}"
      done
    else
      error "       role: ${YELLOW}${AWS_IAM_ROLE_NAME}${RED} cannot be removed, exiting"
      debug "         LOG FILE: ${YELLOW}${LOG}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_role_deletion.log"
      error "           $(cat "${LOG}/${AWS_ROLES}_${AWS_IAM_ROLE_NAME}_role_deletion.log")"
      failed
    fi
  else
    inf "          role: ${YELLOW}${AWS_IAM_ROLE_NAME}${CYAN} removed properly"
  fi
}

associating_instance-to-profile()
{
  if [ $# -ne 2 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs two parameters: ${YELLOW}(1)instance-id, (2)instance_profile-name"
    ERROR_CODE="1"
    failed
  else
    EC2_INSTANCE_ID=${1}
    EC2_INSTANCE_PROFILE_NAME="${2}"
  fi
  inf "Associating EC2 instance: ${YELLOW}${EC2_INSTANCE_ID}${CYAN} to instance profile: ${LIME}${EC2_INSTANCE_PROFILE_NAME}"
  while [[ ! $(aws ${AWS_PROFILE_USE_CHECK[*]} ec2 describe-instance-status --instance-ids ${EC2_INSTANCE_ID} | jq -r '.InstanceStatuses[].InstanceState.Name') == "running" ]]
  do
    for NUMBER in {1..40}
    do
      sleep 0.1
      ProgressBar ${NUMBER} 40
    done
    printf '\n'
  done
  aws ${AWS_PROFILE_USE_CHECK[*]} ec2 associate-iam-instance-profile --instance-id ${EC2_INSTANCE_ID} --iam-instance-profile Name="${EC2_INSTANCE_PROFILE_NAME}" > "${TMP}/${AWS_INSTANCE_PROFILES_ASSOCIATIONS}_${EC2_INSTANCE_ID}_profile_association.json" 2>"${LOG}/${AWS_INSTANCE_PROFILES_ASSOCIATIONS}_${EC2_INSTANCE_ID}_profile_association.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    error "  EC2 instance: ${YELLOW}${EC2_INSTANCE_ID}${RED} cannot be associated to instance-profile: ${LIME}${EC2_INSTANCE_PROFILE_NAME}${RED}, exiting"
    debug "    LOG FILE: ${YELLOW}${LOG}/${AWS_INSTANCE_PROFILES_ASSOCIATIONS}_${EC2_INSTANCE_ID}_profile_association.log"
    error "      $(cat "${LOG}/${AWS_INSTANCE_PROFILES_ASSOCIATIONS}_${EC2_INSTANCE_ID}_profile_association.log")"
    failed
  else
    inf "  EC2 instance: ${YELLOW}${EC2_INSTANCE_ID}${CYAN} associated properly to instance-profile: ${LIME}${EC2_INSTANCE_PROFILE_NAME}"
  fi
}

#disassociate-iam-instance-profile --association-id <value>

aws_S3_bucket_create()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}(1)S3_bucket_name"
    ERROR_CODE="1"
    failed
  else
    S3_BUCKET_NAME="${1}"
  fi
  inf "    S3 bucket: ${YELLOW}${S3_BUCKET_NAME}${CYAN} creating"
  aws ${AWS_PROFILE_USE_CHECK[*]} s3 mb s3://${S3_BUCKET_NAME} > "${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_create.log" 2>&1
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    error "      There was an error creating bucket: ${YELLOW}${S3_BUCKET_NAME}"
    debug "        LOG FILE: ${YELLOW}${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_create.log"
    error "          $(cat "${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_create.log")"
    failed
  else
    inf "      S3 bucket: ${YELLOW}${S3_BUCKET_NAME}${CYAN} has been created"
  fi
}

aws_S3_bucket_encryption()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}(1)S3_bucket_name"
    ERROR_CODE="1"
    failed
  else
    S3_BUCKET_NAME="${1}"
  fi
  aws ${AWS_PROFILE_USE_CHECK[*]} s3api get-bucket-encryption --bucket ${S3_BUCKET_NAME} > "${TMP}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_encryption.json" 2>&1
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    inf "      S3 bucket (${YELLOW}${S3_BUCKET_NAME}${CYAN}) was created without ${DARK_GREEN}encryption${CYAN}, setting it now..."
    aws ${AWS_PROFILE_USE_CHECK[*]} s3api put-bucket-encryption --bucket ${S3_BUCKET_NAME} --server-side-encryption-configuration '{"Rules": [{"ApplyServerSideEncryptionByDefault": {"SSEAlgorithm": "AES256"}}]}'
    ERROR_CODE="$?"
    if [ ${ERROR_CODE} -ne 0 ]
    then
      error "        Encryption on S3 bucket (${YELLOW}${S3_BUCKET_NAME}${RED}) failed"
      debug "          LOG FILE: ${YELLOW}${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_encryption.log"
      failed
    else
      inf "        Encryption on S3 bucket (${YELLOW}${S3_BUCKET_NAME}${CYAN}) applied properly"
    fi
  else
    inf "      S3 bucket (${YELLOW}${S3_BUCKET_NAME}${CYAN}) ${DARK_GREEN}encryption${CYAN} is enabled"
  fi
}

aws_S3_bucket_secure_access_policy()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}(1)S3_bucket_name"
    ERROR_CODE="1"
    failed
  else
    S3_BUCKET_NAME="${1}"
  fi
  S3_BUCKET_SECURE_POLICY_CHECK=$(aws ${AWS_PROFILE_USE_CHECK[*]} s3api get-bucket-policy --bucket ${S3_BUCKET_NAME} --output text 2>/dev/null | jq -r '.Statement[] | select(.Condition.Bool."aws:SecureTransport" == "false") | .Effect')
  if [[ ${S3_BUCKET_SECURE_POLICY_CHECK} == "Deny" ]]
  then
    inf "    S3 bucket (${YELLOW}${S3_BUCKET_NAME}${CYAN}) policy (${DARK_GREEN}SecureTransport${CYAN}) is applied"
  else
    inf "    Applying bucket (${YELLOW}${S3_BUCKET_NAME}${CYAN}) policy (${DARK_GREEN}SecureTransport${CYAN}) for ${YELLOW}${S3_BUCKET_NAME}${CYAN}:"
    echo "{
      \"Statement\":
      [
        {
          \"Effect\": \"Allow\",
          \"Principal\":
          {
            \"AWS\":
            [
              \"${AWS_OWNER_ID}\"
            ]
          },
          \"Action\": \"s3:*\",
          \"Resource\": \"arn:aws:s3:::${S3_BUCKET_NAME}/*\"
        },
        {
          \"Effect\": \"Deny\",
          \"Principal\": \"*\",
          \"Action\": \"*\",
          \"Resource\": \"arn:aws:s3:::${S3_BUCKET_NAME}/*\",
          \"Condition\":
          {
            \"Bool\":
            {
              \"aws:SecureTransport\": \"false\"
            }
          }
        }
      ]
    }" > "${TMP}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_bucket_policy.json"
    aws ${AWS_PROFILE_USE_CHECK[*]} s3api put-bucket-policy --bucket ${S3_BUCKET_NAME} --policy file://"${TMP}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_bucket_policy.json" > "${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_bucket_policy.log" 2>&1
    ERROR_CODE="$?"
    if [ ${ERROR_CODE} -eq 0 ]
    then
      inf "      S3 bucket policy has just been applied"
    else
      error "      S3 bucket policy applying failed"
      debug "        LOG FILE: ${YELLOW}${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_bucket_policy.log"
      failed
    fi
  fi
}

aws_S3_bucket_lifecycle()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}(1)S3_bucket_name"
    ERROR_CODE="1"
    failed
  else
    S3_BUCKET_NAME="${1}"
  fi
  aws ${AWS_PROFILE_USE_CHECK[*]} s3api get-bucket-lifecycle-configuration --bucket ${S3_BUCKET_NAME} > "${TMP}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_lifecycle.json" 2>"${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_lifecycle.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    inf "        S3 bucket (${YELLOW}${S3_BUCKET_NAME}${CYAN}) was created without ${DARK_GREEN}lifecycle${CYAN} configuration, setting it now..."
    aws ${AWS_PROFILE_USE_CHECK[*]} s3api put-bucket-lifecycle-configuration --bucket ${S3_BUCKET} --lifecycle-configuration '{"Rules": [{"Filter":{"Prefix": "/"},"Status": "Enabled","Expiration":{"Days": 30},"ID": "MonthlyCleaning"}]}'
    ERROR_CODE="$?"
    if [ ${ERROR_CODE} -ne 0 ]
    then
      error "          Lifecycle set on S3 bucket (${YELLOW}${S3_BUCKET_NAME}${RED}) failed"
      debug "            LOG FILE: ${YELLOW}${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_lifecycle.log"
      failed
    else
      inf "          Lifecycle on S3 bucket (${YELLOW}${S3_BUCKET_NAME}${CYAN}) applied properly"
    fi
  else
    inf "        S3 bucket (${YELLOW}${S3_BUCKET_NAME}${CYAN}) ${DARK_GREEN}lifesycle${CYAN} is set"
  fi
}

aws_S3_bucket_logging_permissions()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}(1)S3_bucket_name"
    ERROR_CODE="1"
    failed
  else
    S3_BUCKET_NAME="${1}"
  fi
  #ToDo: check if permissions to logging is set properly
  #aws ${AWS_PROFILE_USE_CHECK[*]} s3api get-bucket-acl --bucket ${S3_BUCKET_NAME} > "${TMP}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_logging_permissions.json" 2>"${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_logging_permissions.log"
  #inf "          S3 bucket (${YELLOW}${S3_BUCKET_NAME}${CYAN}) permissions to logging checking..."
  aws ${AWS_PROFILE_USE_CHECK[*]} s3api put-bucket-acl --bucket ${S3_BUCKET_NAME} --grant-write URI=http://acs.amazonaws.com/groups/s3/LogDelivery --grant-read-acp URI=http://acs.amazonaws.com/groups/s3/LogDelivery > "${TMP}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_logging_permissions.json" 2>"${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_logging_permissions.log"
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -ne 0 ]
  then
    error "          S3 bucket (${YELLOW}${S3_BUCKET_NAME}${RED}) permissions to logs cannot be set"
    debug "            LOG FILE: ${YELLOW}${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_logging.log"
    debug "              $(cat "${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_logging.log")"
    failed
  else
    inf "          S3 bucket (${YELLOW}${S3_BUCKET_NAME}${CYAN}) ${DARK_GREEN}permissions to logs${CYAN} has been set properly"
  fi
}


aws_S3_bucket_logging()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}(1)S3_bucket_name"
    ERROR_CODE="1"
    failed
  else
    S3_BUCKET_NAME="${1}"
  fi
  aws_S3_bucket_logging_permissions ${S3_BUCKET_NAME}
  AWS_S3_BUCKET_LOGGING_CHECK=$(aws ${AWS_PROFILE_USE_CHECK[*]} s3api get-bucket-logging --bucket ${S3_BUCKET_NAME} | jq -r '.LoggingEnabled' | head -n1)
  if [ -z ${AWS_S3_BUCKET_LOGGING_CHECK} ]
  then
    inf "              S3 bucket (${YELLOW}${S3_BUCKET_NAME}${CYAN}) has logging not enabled, enabling..."
    aws ${AWS_PROFILE_USE_CHECK[*]} s3api put-bucket-logging --bucket ${S3_BUCKET_NAME} --bucket-logging-status '{"LoggingEnabled": {"TargetBucket": "'${S3_BUCKET_NAME}'","TargetPrefix": "'${S3_BUCKET_NAME}Logs/'"}}' > "${TMP}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_logging.json" 2>"${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_logging.log"
    ERROR_CODE="$?"
    if [ ${ERROR_CODE} -ne 0 ]
    then
      error "                S3 bucket ${YELLOW}${S3_BUCKET_NAME}${CYAN} logging cannot be set"
      debug "                  LOG FILE: ${YELLOW}${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_logging.log"
      debug "                    $(cat "${LOG}/${AWS_S3BUCKETS_DETAILS}_${S3_BUCKET_NAME}_logging.log")"
      failed
    else
      inf "              S3 bucket ${YELLOW}${S3_BUCKET_NAME}${CYAN} ${DARK_GREEN}logging${CYAN} has been set properly"
    fi
  else
    inf "            S3 bucket (${YELLOW}${S3_BUCKET_NAME}${CYAN}) has ${DARK_GREEN}logging${CYAN} enabled"
  fi
}

#ToDo: S3 objects locking
#put-object-lock-configuration
#aws s3api put-object-lock-configuration --bucket my-bucket-with-object-lock --object-lock-configuration '{ "ObjectLockEnabled": "Enabled", "Rule": { "DefaultRetention": { "Mode": "COMPLIANCE", "Days": 50 }}}'
#governance mode 

aws_ec2_security_group_create()
{
if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}(1)security_group_name"
    ERROR_CODE="1"
    failed
  else
    SECURITY_GROUP_NAME="${1}"
  fi
  inf "  Creating default security group for new instance"
  aws ${AWS_PROFILE_USE_CHECK[*]} ec2 create-security-group --description "Temporary security group for EC2 instance" --group-name "${SECURITY_GROUP_NAME}" --vpc-id "${DEFAULT_VPC}" > "${TMP}/${AWS_SECURITY_GROUPS}_${SECURITY_GROUP_NAME}_create_security_group.json"  2>&1
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    export SECURITY_GROUP_ID=$(jq -r '.GroupId' "${TMP}/${AWS_SECURITY_GROUPS}_${SECURITY_GROUP_NAME}_create_security_group.json")
    inf "    Default security group: ${BROWN}${SECURITY_GROUP_ID}${CYAN} has been created properly"
  else
    error "    security group: ${DARK_GREEN}${SECURITY_GROUP_ID}${RED} creation failed, exiting"
    debug "      LOG FILE: ${YELLOW}${TMP}/${AWS_SECURITY_GROUPS}_${SECURITY_GROUP_ID}_create_security_group.json"
    failed
  fi
}

aws_ec2_security_group_delete()
{
if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs one parameter: ${YELLOW}(1)security_group_Id"
    ERROR_CODE="1"
    failed
  else
    SECURITY_GROUP_ID="${1}"
  fi
  inf "    Deleting security group ${YELLOW}${SECURITY_GROUP_ID}"
  aws ${AWS_PROFILE_USE_CHECK[*]} ec2 describe-network-interfaces --filters Name=group-id,Values=${SECURITY_GROUP_ID} > "${TMP}/${AWS_SECURITY_GROUPS}_network_interface_${SECURITY_GROUP_ID}_full.json" 2>&1 
  if [ ! -z $(jq -r '.NetworkInterfaces[].Attachment.InstanceId' "${TMP}/${AWS_SECURITY_GROUPS}_network_interface_${SECURITY_GROUP_ID}_full.json" | head -n1) ]
  then
    for INSTANCE_ID in $(jq -r '.NetworkInterfaces[].Attachment.InstanceId' "${TMP}/${AWS_SECURITY_GROUPS}_network_interface_${SECURITY_GROUP_ID}_full.json")
    do
      warn "      Security group: ${BROWN}${SECURITY_GROUP_ID}${WINE} is still attached to InstanceId: ${YELLOW}${INSTANCE_ID}"
    done
  else
    aws ${AWS_PROFILE_USE_CHECK[*]} ec2 delete-security-group --group-id ${SECURITY_GROUP_ID} > "${TMP}/${AWS_SECURITY_GROUPS}_${SECURITY_GROUP_ID}_delete_security_group.json"  2>&1
    ERROR_CODE="$?"
    if [ ${ERROR_CODE} -eq 0 ]
    then
      inf "      Security group: ${BROWN}${SECURITY_GROUP_ID}${CYAN} has been deleted properly"
    elif grep -q "cannot be deleted by a user" "${TMP}/${AWS_SECURITY_GROUPS}_${SECURITY_GROUP_ID}_delete_security_group.json"
    then
      warn "      Security group: ${BROWN}${SECURITY_GROUP_ID}${RED} cannot be deleted by the user"
    else
      error "      Security group: ${BROWN}${SECURITY_GROUP_ID}${RED} deletion failed, exiting"
      debug "        LOG FILE: ${YELLOW}${TMP}/${AWS_SECURITY_GROUPS}_${SECURITY_GROUP_ID}_delete_security_group.json"
      failed
    fi
  fi
}

aws_security_group_ingress_add()
{
  if [ $# -ne 2 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs two parameter: ${YELLOW}(1)security_group_Id, (2)ingress_network_adress (in CIDR)"
    ERROR_CODE="1"
    failed
  else
    SECURITY_GROUP_ID="${1}"
    INGRESS_CIDR_ADDRESS="${2}"
    if [[ ${INGRESS_CIDR_ADDRESS} == $(echo ${DEFAULT_INET_IP} | awk -F\/ '{print $1}') ]]
    then
      debug "      It is local IP"
    fi
  fi
  if [ -z $(jq -r --arg security_group_id ${SECURITY_GROUP_ID} '.SecurityGroups[] | select(.GroupId == $security_group_id) | .IpPermissions[].IpRanges[].CidrIp' "${TMP}/${AWS_SECURITY_GROUPS}_full.json" | grep "${INGRESS_CIDR_ADDRESS}") ]
  then
    inf "      Adding source address(s): ${LIME}${INGRESS_CIDR_ADDRESS}${CYAN} to ${YELLOW}${SECURITY_GROUP_ID}${CYAN}, to allow ssh to instance(s)"
    aws ${AWS_PROFILE_USE_CHECK[*]} ec2 authorize-security-group-ingress --group-id ${SECURITY_GROUP_ID} --protocol tcp --port 22 --cidr "${INGRESS_CIDR_ADDRESS}" >> "${TMP}/${AWS_SECURITY_GROUPS}_${SECURITY_GROUP_ID}_ingress.json"  2>&1
    ERROR_CODE="$?"
    if [ ${ERROR_CODE} -eq 0 ]
    then
      inf "        Adding source address(s): ${LIME}${INGRESS_CIDR_ADDRESS}${CYAN} succedeed"
      aws ${AWS_PROFILE_USE_CHECK[*]} ec2 describe-security-groups --group-ids ${SECURITY_GROUP_ID} > "${TMP}/${AWS_SECURITY_GROUPS}_${SECURITY_GROUP_ID}_full.json" 2>&1
    else
      error "        Adding source address(s): ${LIME}${INGRESS_CIDR_ADDRESS}${RED} failed, exiting"
      debug "          LOG FILE: ${YELLOW}${TMP}/${AWS_SECURITY_GROUPS}_${SECURITY_GROUP_ID}_ingress.json"
      failed
    fi
  else
    warn "      Source address(s): ${LIME}${INGRESS_CIDR_ADDRESS}${WINE} has already been added to ${YELLOW}${SECURITY_GROUP_ID}${WINE} security group"
  fi
}

event_bridge_remove_target()
{
  if [ $# -ne 2 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs two parameter: ${YELLOW}(1)event_target_Id, (2)event_rule_name"
    ERROR_CODE="1"
    failed
  else
    EVENT_BRIDGE_TARGET_ID="${1}"
    EVENT_BRIDGE_RULE_NAME="${2}"
  fi
  inf "        Target: ${GREEN}${EVENT_BRIDGE_TARGET_ID}${CYAN} will be removed from rule:  ${LIME}${EVENT_BRIDGE_RULE_NAME}"
  aws ${AWS_PROFILE_USE_CHECK[*]} events remove-targets --rule ${EVENT_BRIDGE_RULE_NAME} --ids ${EVENT_BRIDGE_TARGET_ID} > "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}_target_removal_full.json" 2>&1
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    inf "          Target: ${GREEN}${EVENT_BRIDGE_TARGET_ID}${CYAN} removed properly"
  else
    error "          Target: ${GREEN}${EVENT_BRIDGE_TARGET_ID}${RED} wasn't removed properly"
    debug "            LOG FILE: ${YELLOW}${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}_target_removal_full.json"
    failed
  fi
}

event_bridge_remove_rule()
{
  if [ $# -ne 1 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs two parameter: ${YELLOW}(1)event_bridge_rule_name"
    ERROR_CODE="1"
    failed
  else
    EVENT_BRIDGE_RULE_NAME="${1}"
  fi
  inf "    Removing rule: ${LIME}${EVENT_BRIDGE_RULE_NAME}"
  aws ${AWS_PROFILE_USE_CHECK[*]} events delete-rule --name ${EVENT_BRIDGE_RULE_NAME} > "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}_removal_full.json" 2>&1
  ERROR_CODE="$?"
  if [ ${ERROR_CODE} -eq 0 ]
  then
    inf "      Rule: ${LIME}${EVENT_BRIDGE_RULE_NAME}${CYAN} removed properly"
  else
    error "      Rule: ${LIME}${EVENT_BRIDGE_RULE_NAME}${RED} wasn't removed properly"
    debug "        LOG FILE: ${YELLOW}${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}_removal_full.json"
    failed
  fi
}

events_create_cron_rule()
{
  if [ $# -ne 2 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs two parameter: ${YELLOW}(1)event_rule_name, (2)cron_event_schedule"
    ERROR_CODE="1"
    failed
  else
    EVENT_BRIDGE_RULE_NAME="${1}"
    EVENT_BRIDGE_RULE_NAME_SCHEDULE="${2}"
  fi
  EVENT_BRIDGE_RULE_NAME_CHECK=$(jq -r --arg event_bridge_rule_name ${EVENT_BRIDGE_RULE_NAME} '.Rules[] | select(.Name == $event_bridge_rule_name) | .Arn' "${TMP}/${AWS_EVENTS_RULES}_full.json")
  if [ -z ${EVENT_BRIDGE_RULE_NAME_CHECK} ]
  then
    inf "    Adding event rule: ${LIME}${EVENT_BRIDGE_RULE_NAME}${CYAN} with schedule: ${BROWN}\"${EVENT_BRIDGE_RULE_NAME_SCHEDULE}\""
    aws ${AWS_PROFILE_USE_CHECK[*]} events put-rule --schedule-expression "${EVENT_BRIDGE_RULE_NAME_SCHEDULE}" --name ${EVENT_BRIDGE_RULE_NAME} > "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}_full.json" 2>"${LOG}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}.log"
    ERROR_CODE="$?"
    if [ ${ERROR_CODE} -eq 0 ]
    then
      inf "      Event rule: ${LIME}${EVENT_BRIDGE_RULE_NAME}${CYAN} added properly"
      debug "        Slack notification...."
      source "${SCRIPTS_HOME}/slack_notification_event_rule"
    else
      error "      Event rule: ${LIME}${EVENT_BRIDGE_RULE_NAME}${RED} failed to add"
      debug "        LOG FILE: ${YELLOW}${LOG}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}.log"
      failed
    fi
  else
    EVENT_BRIDGE_TARGET_AMOUNT=$(jq -r '.Targets[].Arn' "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}_targets_full.json" | wc -l)
    if [ ${EVENT_BRIDGE_TARGET_AMOUNT} -ge 5 ]
    then
      warn "    Event rule: ${LIME}${EVENT_BRIDGE_RULE_NAME}${WINE} has already full with targets (${RED}5${WINE})"
    else
      inf "    ${WINE}Event rule: ${LIME}${EVENT_BRIDGE_RULE_NAME}${WINE} already exists (targets: ${GREEN}${EVENT_BRIDGE_TARGET_AMOUNT}${CYAN})"
    fi
  fi
}

events_list_of_rules()
{
  aws ${AWS_PROFILE_USE_CHECK[*]} events list-rules > "${TMP}/${AWS_EVENTS_RULES}_full.json" 2>"${LOG}/${AWS_EVENTS_RULES}.log"
}

events_list_of_all_targets()
{
  if [ -s "${TMP}/${AWS_EVENTS_BUSES}_full.json" ]
  then
    for EVENT_BUS in $(jq -r '.EventBuses[].Name' "${TMP}/${AWS_EVENTS_BUSES}_full.json")
    do
      EVENT_BUS_NAME=${EVENT_BUS}
      EVENT_BUS_ARN="$(jq -r --arg event_bus_name ${EVENT_BUS_NAME} '.EventBuses[] | select(.Name == $event_bus_name) | .Arn' "${TMP}/${AWS_EVENTS_BUSES}_full.json")"
      if [ -s "${TMP}/${AWS_EVENTS_RULES}_full.json" ] && [ ! -z $(jq -r --arg aws_default_name ${AWS_DEFAULT_NAME} --arg event_bus_name ${EVENT_BUS_NAME} '.Rules[] | select(.Name | contains($aws_default_name) | not) | select(.EventBusName == $event_bus_name) | select(.ManagedBy == "schemas.amazonaws.com" | not) | .Name' "${TMP}/${AWS_EVENTS_RULES}_full.json" | head -n1) ]
      then
        for EVENT_RULE in $(jq -r --arg aws_default_name ${AWS_DEFAULT_NAME} --arg event_bus_name ${EVENT_BUS_NAME} '.Rules[] | select(.Name | contains($aws_default_name) | not) | select(.EventBusName == $event_bus_name) | select(.ManagedBy == "schemas.amazonaws.com" | not) | .Name' "${TMP}/${AWS_EVENTS_RULES}_full.json")
        do
          (
            aws ${AWS_PROFILE_USE_CHECK[*]} events list-targets-by-rule --event-bus-name ${EVENT_BUS_NAME} --rule ${EVENT_RULE} > "${TMP}/${AWS_EVENTS_RULES}_${EVENT_RULE}_targets_full.json" 2>"${LOG}/${AWS_EVENTS_RULES}_${EVENT_RULE}_targets.log"
            EVENT_RULE_AMOUNTS_TARGET=$(grep Arn "${TMP}/${AWS_EVENTS_RULES}_${EVENT_RULE}_targets_full.json" | wc -l)
            echo "${EVENT_RULE}~${EVENT_RULE_AMOUNTS_TARGET}~${AWS_EVENTS_RULES}_${EVENT_RULE}_targets_full.json" >> "${TMP}/${AWS_EVENTS_RULES}_target_amount.csv"
          ) &
        done
      fi
    done
  fi
  wait
}

#aws ${AWS_PROFILE_USE_CHECK[*]} events create-event-bus --name ${AWS_COMMON_NAME}-EC2_scripts_deployment_bus > "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_BUS}_full.json" 2>&1

lambda_add_permission_to_trust_principal()
{
  if [ $# -ne 4 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs four parameter: ${YELLOW}(1)lambda_function_name, (2)event-name, (3)service-proncipal, (4)event_bridge-rule_name"
    ERROR_CODE="1"
    failed
  else
    AWS_LAMBDA_FUNCTION_NAME=${1}
    EVENT_BRIDGE_EVENT_NAME=${2}
    SERVICE_PRINCIPAL=${3}
    EVENT_BRIDGE_RULE_NAME=${4}
    PERMISSIONS_ACTION="lambda:InvokeFunction"
  fi
  aws ${AWS_PROFILE_USE_CHECK[*]} lambda get-policy --function-name ${AWS_LAMBDA_FUNCTION_NAME} --output text 2>"${LOG}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_EVENT_NAME}_trust.log" | jq -r > "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_EVENT_NAME}_trust_full.json" 2>>"${LOG}/${AWS_LAMBDA_FUNCTION_NAME}_${EVENT_BRIDGE_EVENT_NAME}_trust.log"

  if [ -s "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_EVENT_NAME}_trust_full.json" ]
  then
    LAMBDA_FUNCTION_ARN_FROM_EVENT=$(jq -r '.Statement[].Resource' "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_EVENT_NAME}_trust_full.json")
    SID_FROM_EVENT=$(jq -r '.Statement[].Sid' "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_EVENT_NAME}_trust_full.json")
    EVENT_BRIDGE_RULE_ARN=$(jq -r '.Statement[].Condition.ArnLike."AWS:SourceArn"' "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_EVENT_NAME}_trust_full.json")
    PERMISSION_EVENTBRIDGE_LAMBDA=$(jq -r '.Statement[].Action' "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_EVENT_NAME}_trust_full.json")
    if [[ ${EVENT_BRIDGE_EVENT_NAME} == ${SID_FROM_EVENT} ]]
    then
      if [[ ${PERMISSIONS_ACTION} == ${PERMISSION_EVENTBRIDGE_LAMBDA} ]]
      then
        inf "      ${WINE}Appropriate permissions and trust are set properly already"
      else
        warn "      ${RED}Trust has been set but with different permissions... it might not work finally"
      fi
    fi
  else
    inf "      Adding trust ${DARK_GREEN}${SERVICE_PRINCIPAL}${CYAN} and scope permissions to the rule: ${LIME}${EVENT_BRIDGE_RULE_NAME}"
    if [ -s "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}_full.json" ]
    then
      EVENT_BRIDGE_RULE_ARN=$(jq -r '.RuleArn' "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}_full.json")
    elif [ -s "${TMP}/${AWS_EVENTS_RULES}_full.json" ]
    then
      EVENT_BRIDGE_RULE_ARN=$(jq -r --arg event_bridge_rule_name ${EVENT_BRIDGE_RULE_NAME} '.Rules[] | select(.Name == $event_bridge_rule_name) | .Arn' "${TMP}/${AWS_EVENTS_RULES}_full.json")
    fi
    aws ${AWS_PROFILE_USE_CHECK[*]} lambda add-permission --function-name ${AWS_LAMBDA_FUNCTION_NAME} --statement-id ${EVENT_BRIDGE_EVENT_NAME} --action "${PERMISSIONS_ACTION}" --principal ${SERVICE_PRINCIPAL} --source-arn ${EVENT_BRIDGE_RULE_ARN} > "${TMP}/${AWS_LAMBDA_FUNCTION_NAME}_${EVENT_BRIDGE_EVENT_NAME}_trust.json" 2> "${LOG}/${AWS_LAMBDA_FUNCTION_NAME}_${EVENT_BRIDGE_EVENT_NAME}_trust.log"
    ERROR_CODE="$?"
    if [ ${ERROR_CODE} -eq 0 ]
    then
      inf "        Event rule ${LIME}${EVENT_BRIDGE_RULE_NAME}${CYAN} trusts ${DARK_GREEN}${SERVICE_PRINCIPAL}"
    else
      error "        Event rule ${LIME}${EVENT_BRIDGE_RULE_NAME}${CYAN} trust cannot be set"
      debug "          LOG FILE: ${YELLOW}${LOG}/${AWS_LAMBDA_FUNCTION_NAME}_${EVENT_BRIDGE_EVENT_NAME}_trust.log"
      error "            $(cat ${LOG}/${AWS_LAMBDA_FUNCTION_NAME}_${EVENT_BRIDGE_EVENT_NAME}_trust.log)"
      failed
    fi
  fi
}

events_add_target_to_rule()
{
  if [ $# -ne 2 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs two parameter: ${YELLOW}(1)event_target_Id, (2)event_rule_name"
    ERROR_CODE="1"
    failed
  else
    EVENT_BRIDGE_TARGET_ID=${1}
    EVENT_BRIDGE_RULE_NAME=${2}
  fi
  EVENT_BRIDGE_TARGET_ARN_CHECK=$(jq -r --arg arn ${EC2_LAMBDA_SCRIPT_ARN} '.Targets[] | select(.Arn == $arn) | .Arn' "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}_targets_full.json" 2>/dev/null | sort -u)
  EVENT_BRIDGE_TARGET_AMOUNT=$(jq -r '.Targets[].Arn' "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}_targets_full.json" 2>/dev/null | wc -l)
  if [ ! -z ${EVENT_BRIDGE_TARGET_ARN_CHECK} ]
  then
    inf "        ${WINE}Target: ${GREEN}${EVENT_BRIDGE_TARGET_ID}${WINE} is already added to rule: ${LIME}${EVENT_BRIDGE_RULE_NAME}"
  elif [ -z ${EVENT_BRIDGE_TARGET_ARN_CHECK} ] && [ ${EVENT_BRIDGE_TARGET_AMOUNT} -lt 5 ]
  then
    inf "      Target: ${GREEN}${EVENT_BRIDGE_TARGET_ID}${CYAN} will be added to rule: ${LIME}${EVENT_BRIDGE_RULE_NAME}"
    aws ${AWS_PROFILE_USE_CHECK[*]} events put-targets --rule ${EVENT_BRIDGE_RULE_NAME} --targets ${EVENT_BRIDGE_TARGET_ID} > "${TMP}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}_target${RANDOM_ID_GEN}_full.json" 2>"${LOG}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}_target${RANDOM_ID_GEN}.log"
    ERROR_CODE="$?"
    if [ ${ERROR_CODE} -eq 0 ]
    then
      inf "        Target: ${GREEN}${EVENT_BRIDGE_TARGET_ID}${CYAN} added properly"
      debug "          Slack notification...."
      source "${SCRIPTS_HOME}/slack_notification_lambda_target"
    else
      error "        Target: ${GREEN}${EVENT_BRIDGE_TARGET_ID}${RED} wasn't added"
      debug "          LOG FILE: ${YELLOW}${LOG}/${AWS_EVENTS_RULES}_${EVENT_BRIDGE_RULE_NAME}_target${RANDOM_ID_GEN}.log"
      failed
    fi
  elif [ ${EVENT_BRIDGE_TARGET_AMOUNT} -ge 5 ]
  then
    warn "      Target: ${GREEN}${EVENT_BRIDGE_TARGET_ID}${CYAN} cannot be added to rule: ${LIME}${EVENT_BRIDGE_RULE_NAME}${WINE} due to quota"
  fi
}

aws_run_EC2_code()
{
  if [ $# -ne 4 ]
  then
    error "Function ${LIME}${FUNCNAME[0]}${RED} needs five parameters: ${YELLOW}(1)repository, (2)branch, (3)script-name, (4)script-parameters"
    ERROR_CODE="1"
    failed
  else
    REPOSITORY_NAME="${1}"
    REPOSITORY_BRANCH="${2}"
    RUN_SCRIPT_NAME="${3}"
    RUN_SCRIPT_PARAMETERS="${4}"
  fi
  inf ""
  inf "${LIGHT_BLUE} COMMAND TEST "
  inf "Test of running command:"
  inf "  Running ${YELLOW}${RUN_SCRIPT_NAME} ${BROWN}${RUN_SCRIPT_PARAMETERS}${CYAN} for TESTING PURPOSES and as an EXAMPLE only"
  ssh -o "StrictHostKeyChecking no" -n -f ${DEPLOY_USER}@${AWS_INSTANCE_DETAILS_IP} "nohup sh -c 'source /etc/profile ; cd \${HOME} ; cd \${HOME}/${REPOSITORY_NAME} ; git checkout ${REPOSITORY_BRANCH} > /dev/null 2>&1; \${HOME}/${REPOSITORY_NAME}/${RUN_SCRIPT_NAME} ${SCRIPT_PARAMETERS}' > \${HOME}/${SCRIPT_NAME}_${CURRENT_TIMESTAMP}.log 2>&1 & echo "'$!'" > \${HOME}/${SCRIPT_NAME}_${CURRENT_TIMESTAMP}.pid"
  ssh -o "StrictHostKeyChecking no" ${DEPLOY_USER}@${AWS_INSTANCE_DETAILS_IP} "PID_SCRIPT=\$(cat \${HOME}/${SCRIPT_NAME}_${CURRENT_TIMESTAMP}.pid); tail --pid \${PID_SCRIPT} -n +1 -f \${HOME}/${SCRIPT_NAME}_${CURRENT_TIMESTAMP}.log"
  inf "${LIGHT_BLUE} COMMAND TEST "
  inf ""
}

debug "${YELLOW}[ ${LIME}$(echo $(caller | awk '{print $2}') | awk -F\/ '{print $NF}') ${YELLOW}calls (in line: ${LIME}$(caller | awk '{print $1}')${YELLOW}) ${LIME}$(echo ${BASH_SOURCE} | awk -F\/ '{print $NF}')${YELLOW} ]"
